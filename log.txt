C:\Users\bscard\miniconda3\python.exe "C:/Users/bscard/Documents/Pycharm Projects/nyt_sentiment_analyzer/nyt_sentiment_analyzer.py"

DataFrame Sample
  Unnamed: 0  ... slideshow_credits
0          0  ...               NaN
1          1  ...               NaN
2          2  ...               NaN
3          3  ...               NaN
4          4  ...               NaN

[5 rows x 31 columns]

DataFrame Shape: (46563, 31)

DataFrame Metadata
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 46563 entries, 0 to 46562
Data columns (total 31 columns):
Unnamed: 0                 46563 non-null object
abstract                   45579 non-null object
web_url                    46559 non-null object
snippet                    44603 non-null object
lead_paragraph             44806 non-null object
source                     45569 non-null object
multimedia                 46563 non-null object
keywords                   46563 non-null object
pub_date                   46563 non-null object
document_type              46563 non-null object
news_desk                  45774 non-null object
section_name               46559 non-null object
type_of_material           45496 non-null object
_id                        46563 non-null object
word_count                 46563 non-null float64
uri                        46563 non-null object
headline_main              46563 non-null object
headline_kicker            8585 non-null object
headline_content_kicker    0 non-null float64
headline_print_headline    28511 non-null object
headline_name              0 non-null float64
headline_seo               0 non-null float64
headline_sub               0 non-null float64
byline_original            38974 non-null object
byline_person              46563 non-null object
byline_organization        4945 non-null object
subsection_name            26972 non-null object
print_section              21486 non-null object
print_page                 23522 non-null object
candidate                  46563 non-null object
slideshow_credits          12 non-null object
dtypes: float64(5), object(26)
memory usage: 11.0+ MB
None

Preprocessed DataFrame!

New DataFrame Shape: (18486, 6)

Generated Date Features & reset index!

Index(['headline_main', 'web_url', 'text', 'word_count', 'pub_date',
       'candidate', 'year', 'month', 'day', 'dayofweek', 'hour'],
      dtype='object')

Filtered out articles prior to 2019!

DataFrame Shape: (11187, 11)

Generated TextBlob Sentiment Scores!

['What’s on TV Tuesday: Leslie Jones and the Democratic Debate Leslie Jones looks back at her life in a new stand-up special, and the first Democratic presidential debate of the year airs on CNN.'
 'The Most Important Week of the Democratic Primary in 2019 How a series of turning points in mid-October explains the state of the race today and can serve as a cheat sheet for the casual 2020 primary observer.'
 'What Do You Think About Beto? What this country needs is a skateboarder president.'
 'Here Is Every 2020 Democrat, Roasted by Haiku Because there are too many candidates to use full sentences.'
 'Where in N.Y.C. to Watch the Democratic Debates Wednesday: Two nights of debates means two nights of watch parties across the city.'
 "Democrats, Prince Charles, N.F.L.: Your Monday Briefing Here's what you need to know."
 'The Awkward but Essential Art of Office Chitchat We regret to inform you that you need to make small talk with your co-workers. Here’s how to master it.'
 'Naomi Wolf’s Publisher Cancels U.S. Release of ‘Outrages’ The book had been postponed for months after errors were uncovered earlier this year.'
 'Tape Made Public of Trump Discussing Ukraine With Donors The recording from a dinner in 2018 showed that the president spent an hour with two key players in the Ukraine pressure campaign. He has repeatedly said he does not know them.'
 'Schiff sought to head off the defense. Now it’s coming for him. President Trump’s defense team wasted little time on Saturday coming straight after the House managers on the process, playing a clip at the outset of Mr. Schiff at a hearing last year'
 '\'Denial of Justice\': Britain Rebukes U.S. for Not Giving Up Diplomat\'s Wife Britain criticized the United States on Friday for refusing to extradite a U.S. diplomat\'s wife who was involved in a car crash that killed a British teenager, saying it amounted to a "denial of justice".'
 'Tougher Huawei Restrictions Stall After Defense Department Objects Proposed changes to further limit American shipments to Huawei have been delayed amid arguments they could backfire.'
 'In Private, Republicans Admit They Acquitted Trump Out of Fear One journalist remarked to me, “How in the world can these senators walk around here upright when they have no backbone?”'
 'What’s on TV Tuesday: ‘Contact’ and the State of the Union A film starring Jodie Foster is airing. And President Trump delivers his third State of the Union Address.'
 "Saudi Arabia Blocks Iran From Islamic Grouping's Meeting: Tehran Saudi Arabia has barred an Iranian delegation from an Organization of Islamic Cooperation (OIC) meeting in Jeddah on Monday where U.S. President Donald Trump's Middle East peace plan will be discussed, the Iranian foreign ministry said."
 'Judge Reverses Convictions of Activists Who Left Water for Migrants A federal judge found that four volunteers with the group “No More Deaths” were acting on their religious beliefs when they left food and water for migrants in the desert.'
 'Polling: Americans Dissatisfied With the State of the Union The turbulence of impeachment, a contentious presidential campaign and a global virus health threat confront President Donald Trump as he prepares to deliver his State of the Union address Tuesday night. But one thing about the Trump era has remained remarkably steady: public opinion on the president.'
 'How Trump Made a Writer of Thrillers Stick to Facts Richard North Patterson wrote best-selling novels about presidents, until he decided that the political moment was too strange to make anything up.'
 'Wells Fargo Is Reviewing Its Account-Closing Practices The chief executive, C. Allen Parker, told Senator Elizabeth Warren that the bank had begun an “extensive review” of overdraft fees for such accounts in response to a New York Times article.'
 'In Tribute to Cummings, Obama Hints at Rebuke of Trump The former president said that Representative Elijah E. Cummings showed that “you’re not a sucker to have integrity.”'
 "Boris Johnson, United Nations, Puerto Rico: Your Tuesday Briefing  Here's what you need to know"
 "Ukraine, Emmy Awards, Thomas Cook: Your Monday Briefing Here's what you need to know."
 'Hong Kong, Impeachment Hearings, Tom Hanks: Your Thursday Briefing Here’s what you need to know.'
 'There’s No Boom in Youngstown, but Blue-Collar Workers Are Sticking With Trump The recovery, which has brought low unemployment and rising wages elsewhere, hasn’t really lifted industrial northeast Ohio. But President Trump has lost little of his support there.'
 'Biden Makes First Campaign Appearance in South Carolina, Key Primary State The speech indicated how Mr. Biden will bring his “working-class Joe” brand to a more diverse Democratic electorate, with black voters playing a dominant role.'
 'Sri Lanka, Notre-Dame, Joe Biden: Your Friday Briefing A strategy shift for ISIS.']

Computed labels for Modeling

['positive' 'neutral' 'negative']

positive    4599
neutral     3558
negative    1862
Name: sentiment_label, dtype: int64

0    120
1    265
2    194
3    202
4     83
Name: char_count, dtype: int64

0    Impeachment North Korea Eddie Murphy Your Week...
1    Warren Souvenir Wine Bottle Pops Up in Big Don...
2    Impeachment and a Wine Cave Debate This Week i...
3    Buttigieg Leads Rivals in Wall Street Contribu...
4    Guest Lineups for the Sunday News Shows Guest ...
Name: text_feat, dtype: object

Index(['headline_main', 'web_url', 'text', 'word_count', 'pub_date',
       'candidate', 'year', 'month', 'day', 'dayofweek', 'hour', 'polarity',
       'subjectivity', 'sentiment_label', 'char_count', 'text_feat'],
      dtype='object')

DataFrame descriptive statistics:
{'word_count': count    10019.000000
mean      1045.977044
std        944.576796
min          0.000000
25%        534.000000
50%        969.000000
75%       1345.000000
max      20056.000000
Name: word_count, dtype: float64, 'year': count    10019.000000
mean      2019.264997
std          0.441353
min       2019.000000
25%       2019.000000
50%       2019.000000
75%       2020.000000
max       2020.000000
Name: year, dtype: float64, 'month': count    10019.000000
mean         6.721429
std          4.237385
min          1.000000
25%          2.000000
50%          7.000000
75%         11.000000
max         12.000000
Name: month, dtype: float64, 'day': count    10019.000000
mean        16.294640
std          9.224536
min          1.000000
25%          8.000000
50%         17.000000
75%         25.000000
max         31.000000
Name: day, dtype: float64, 'dayofweek': count    10019.000000
mean         2.605549
std          1.753960
min          0.000000
25%          1.000000
50%          3.000000
75%          4.000000
max          6.000000
Name: dayofweek, dtype: float64, 'hour': count    10019.000000
mean        13.043717
std          6.818533
min          0.000000
25%          9.000000
50%         14.000000
75%         19.000000
max         23.000000
Name: hour, dtype: float64, 'polarity': count    10019.000000
mean         0.071684
std          0.212364
min         -1.000000
25%          0.000000
50%          0.018182
75%          0.171429
max          1.000000
Name: polarity, dtype: float64, 'subjectivity': count    10019.000000
mean         0.351452
std          0.257319
min          0.000000
25%          0.125000
50%          0.360000
75%          0.500000
max          1.000000
Name: subjectivity, dtype: float64, 'char_count': count    10019.000000
mean       198.683501
std         69.853475
min         30.000000
25%        152.000000
50%        199.000000
75%        239.000000
max        737.000000
Name: char_count, dtype: float64}

The reduced dataframe has 10 columns.

trump                     1767
president                 1207
is                        1203
as                         787
impeachment                655
new                        641
democratic                 595
are                        592
an                         574
has                        510
democrats                  489
was                        483
biden                      449
2020                       432
will                       430
house                      418
said                       408
presidential               393
not                        390
donald                     382
donald trump               379
more                       367
president trump            346
candidates                 333
warren                     315
president donald           312
president donald trump     312
debate                     295
state                      294
sanders                    284
dtype: int64

<class 'pandas.core.frame.DataFrame'>
Int64Index: 10019 entries, 0 to 11186
Data columns (total 18 columns):
headline_main      10019 non-null object
web_url            10016 non-null object
text               10019 non-null object
word_count         10019 non-null float64
pub_date           10019 non-null datetime64[ns, UTC]
candidate          10019 non-null object
year               10019 non-null int64
month              10019 non-null int64
day                10019 non-null int64
dayofweek          10019 non-null int64
hour               10019 non-null int64
polarity           10019 non-null float64
subjectivity       10019 non-null float64
sentiment_label    10019 non-null object
char_count         10019 non-null int64
text_feat          10019 non-null object
PC1                8851 non-null float64
PC2                8851 non-null float64
dtypes: datetime64[ns, UTC](1), float64(5), int64(6), object(6)
memory usage: 1.8+ MB
None

C:\Users\bscard\miniconda3\lib\site-packages\pandas\plotting\_matplotlib\converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.

To register the converters:
	>>> from pandas.plotting import register_matplotlib_converters
	>>> register_matplotlib_converters()
  warnings.warn(msg, FutureWarning)
Instantiated list of text models!

DataFrame shape: (2004, 10)

DataFrame head:                                               text_feat  ...  sentiment_label
7809  Lisa Page Ex Lawyer Whose Texts Criticized Tru...  ...          neutral
5590  This Mexican Chef Is Having a Very Good Year G...  ...          neutral
3329  Why be Democrats Talking About Impeachment Bec...  ...         positive
1728  Democratic Presidential Hopeful Klobuchar Sets...  ...          neutral
9926  Jeffrey Epstein Gun Control Simone Biles Your ...  ...          neutral

[5 rows x 10 columns]

DataFrame labels; positive    937
neutral     717
negative    350
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
1922   Elizabeth Warren Wants to Cancel Student Loans...  ...          neutral
10223  Trump Presses His Argument of a Border Crisis ...  ...          neutral
8313   Big Business Says It Will Tackle Climate Chang...  ...          neutral
2055   Unable to Post Bail You Will Pay for That for ...  ...         negative
1951   Eliminating Child Poverty With a Government Ch...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    908
neutral     703
negative    393
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
10432  The Impeachment Questions We Were Afraid to As...  ...         positive
1304   Who Won the Debate Experts Weigh In There be l...  ...         positive
9176   Years Later Native American Tribe in Montana G...  ...          neutral
2669   In a Collection of Tributes the Gang Is All He...  ...         positive
8691   Trial date be set for Lev Parnas Parnas have s...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    907
neutral     697
negative    400
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                               text_feat  ...  sentiment_label
5266  How Can You Put Life of Onstage With Puppets I...  ...          neutral
1432  Momentum for Harris Big Haul for Buttigieg Thi...  ...         negative
1515  Should College Be Free The Democratic Party be...  ...          neutral
7793  Trump Possible Policy Shift on the Taliban A r...  ...         positive
5133  You Oughta The Road to Making a Anthem a Broad...  ...          neutral

[5 rows x 10 columns]

DataFrame labels; positive    910
neutral     733
negative    361
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
7242   Impeachment Briefing What Happened Today Anoth...  ...         positive
10153  Wartime Secrets and Intrigue From the Hotel Ri...  ...         positive
4061   Joe Biden and the Apologies That be Politician...  ...         negative
6344   Elizabeth Warren Has a Poet on Her Team Here W...  ...          neutral
10739  Trump Wants a Fight Pelosi Can Hit Back With r...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    935
neutral     715
negative    354
Name: sentiment_label, dtype: int64

Split DataFrames into 5-Fold datasets!

Starting Model Training!

Pipeline(memory=None,
         steps=[('vectorizer',
                 CountVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.int64'>, encoding='utf-8',
                                 input='content', lowercase=True, max_df=1.0,
                                 max_features=None, min_df=1,
                                 ngram_range=(1, 2), preprocessor=None,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be', 'a',
                                             'and', 'any', 'be', 'a', '...
                                             'be', 'below', 'between', 'both',
                                             'but', 'by', 'can', 'com', 'can',
                                             'do', 'do', 'doe', ...],
                                 strip_accents=None,
                                 token_pattern='(?u)\\b\\w\\w+\\b',
                                 tokenizer=None, vocabulary=None)),
                ('dim_red',
                 SelectKBest(k=300,
                             score_func=<function chi2 at 0x00000237811AE158>)),
                ('clf',
                 OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0,
                                                             class_prior=None,
                                                             fit_prior=True),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6631316281971303

Test Set Accuracy
0.4389027431421446

Confusion matrix
[[  2  21  47]
 [  6  49  88]
 [ 13  50 125]]

Classification report
              precision    recall  f1-score   support

    negative       0.10      0.03      0.04        70
     neutral       0.41      0.34      0.37       143
    positive       0.48      0.66      0.56       188

    accuracy                           0.44       401
   macro avg       0.33      0.35      0.32       401
weighted avg       0.39      0.44      0.40       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6444167186525265

Test Set Accuracy
0.4139650872817955

Confusion matrix
[[ 10  14  54]
 [ 14  37  90]
 [ 18  45 119]]

Classification report
              precision    recall  f1-score   support

    negative       0.24      0.13      0.17        78
     neutral       0.39      0.26      0.31       141
    positive       0.45      0.65      0.53       182

    accuracy                           0.41       401
   macro avg       0.36      0.35      0.34       401
weighted avg       0.39      0.41      0.38       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6431690580162196

Test Set Accuracy
0.4239401496259352

Confusion matrix
[[  4  21  55]
 [ 13  26 100]
 [ 14  28 140]]

Classification report
              precision    recall  f1-score   support

    negative       0.13      0.05      0.07        80
     neutral       0.35      0.19      0.24       139
    positive       0.47      0.77      0.59       182

    accuracy                           0.42       401
   macro avg       0.32      0.34      0.30       401
weighted avg       0.36      0.42      0.37       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.669369931378665

Test Set Accuracy
0.3865336658354115

Confusion matrix
[[  5  28  39]
 [  9  43  95]
 [ 16  59 107]]

Classification report
              precision    recall  f1-score   support

    negative       0.17      0.07      0.10        72
     neutral       0.33      0.29      0.31       147
    positive       0.44      0.59      0.51       182

    accuracy                           0.39       401
   macro avg       0.31      0.32      0.30       401
weighted avg       0.35      0.39      0.36       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6319401122894572

Test Set Accuracy
0.4513715710723192

Confusion matrix
[[  4  19  48]
 [  5  24 114]
 [ 13  21 153]]

Classification report
              precision    recall  f1-score   support

    negative       0.18      0.06      0.09        71
     neutral       0.38      0.17      0.23       143
    positive       0.49      0.82      0.61       187

    accuracy                           0.45       401
   macro avg       0.35      0.35      0.31       401
weighted avg       0.39      0.45      0.38       401


5-fold cross-validated Accuracy: 0.42294264339152116

5-fold cross-validated F1 score: 0.31548670539642504

Pipeline(memory=None,
         steps=[('vectorizer',
                 TfidfVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.float64'>,
                                 encoding='utf-8', input='content',
                                 lowercase=True, max_df=1.0, max_features=None,
                                 min_df=1, ngram_range=(1, 2), norm='l2',
                                 preprocessor=None, smooth_idf=True,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be...
                                 strip_accents=None, sublinear_tf=False,
                                 token_pattern='(?u)\\b\\w\\w+\\b',
                                 tokenizer=None, use_idf=True,
                                 vocabulary=None)),
                ('scaler',
                 StandardScaler(copy=True, with_mean=False, with_std=True)),
                ('dim_red',
                 SelectKBest(k=300,
                             score_func=<function chi2 at 0x00000237811AE158>)),
                ('clf',
                 OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0,
                                                             class_prior=None,
                                                             fit_prior=True),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.527760449157829

Test Set Accuracy
0.4488778054862843

Confusion matrix
[[  2   0  68]
 [  8   1 134]
 [ 10   1 177]]

Classification report
              precision    recall  f1-score   support

    negative       0.10      0.03      0.04        70
     neutral       0.50      0.01      0.01       143
    positive       0.47      0.94      0.62       188

    accuracy                           0.45       401
   macro avg       0.36      0.33      0.23       401
weighted avg       0.41      0.45      0.31       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5346225826575172

Test Set Accuracy
0.42144638403990026

Confusion matrix
[[  3   1  74]
 [  4   0 137]
 [ 15   1 166]]

Classification report
              precision    recall  f1-score   support

    negative       0.14      0.04      0.06        78
     neutral       0.00      0.00      0.00       141
    positive       0.44      0.91      0.59       182

    accuracy                           0.42       401
   macro avg       0.19      0.32      0.22       401
weighted avg       0.23      0.42      0.28       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5221459762944479

Test Set Accuracy
0.4613466334164589

Confusion matrix
[[  9   1  70]
 [ 11   5 123]
 [ 10   1 171]]

Classification report
              precision    recall  f1-score   support

    negative       0.30      0.11      0.16        80
     neutral       0.71      0.04      0.07       139
    positive       0.47      0.94      0.63       182

    accuracy                           0.46       401
   macro avg       0.49      0.36      0.29       401
weighted avg       0.52      0.46      0.34       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5208983156581409

Test Set Accuracy
0.4339152119700748

Confusion matrix
[[  1   0  71]
 [  7   3 137]
 [  6   6 170]]

Classification report
              precision    recall  f1-score   support

    negative       0.07      0.01      0.02        72
     neutral       0.33      0.02      0.04       147
    positive       0.45      0.93      0.61       182

    accuracy                           0.43       401
   macro avg       0.28      0.32      0.22       401
weighted avg       0.34      0.43      0.29       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5570804741110418

Test Set Accuracy
0.4488778054862843

Confusion matrix
[[  6   1  64]
 [  5   1 137]
 [ 13   1 173]]

Classification report
              precision    recall  f1-score   support

    negative       0.25      0.08      0.13        71
     neutral       0.33      0.01      0.01       143
    positive       0.46      0.93      0.62       187

    accuracy                           0.45       401
   macro avg       0.35      0.34      0.25       401
weighted avg       0.38      0.45      0.31       401


5-fold cross-validated Accuracy: 0.44289276807980055

5-fold cross-validated F1 score: 0.24137516303453213

Pipeline(memory=None,
         steps=[('vectorizer',
                 CountVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.int64'>, encoding='utf-8',
                                 input='content', lowercase=True, max_df=1.0,
                                 max_features=None, min_df=1,
                                 ngram_range=(1, 2), preprocessor=None,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be', 'a',
                                             'and', 'any', 'be', 'a', '...
                 SelectKBest(k=300,
                             score_func=<function chi2 at 0x00000237811AE158>)),
                ('clf',
                 OneVsRestClassifier(estimator=SVC(C=1.0, break_ties=False,
                                                   cache_size=200,
                                                   class_weight='balanced',
                                                   coef0=0.0,
                                                   decision_function_shape='ovr',
                                                   degree=3, gamma='scale',
                                                   kernel='rbf', max_iter=-1,
                                                   probability=True,
                                                   random_state=42,
                                                   shrinking=True, tol=0.001,
                                                   verbose=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.7186525265127885

Test Set Accuracy
0.38403990024937656

Confusion matrix
[[ 12  21  37]
 [ 24  38  81]
 [ 37  47 104]]

Classification report
              precision    recall  f1-score   support

    negative       0.16      0.17      0.17        70
     neutral       0.36      0.27      0.31       143
    positive       0.47      0.55      0.51       188

    accuracy                           0.38       401
   macro avg       0.33      0.33      0.33       401
weighted avg       0.38      0.38      0.38       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.7117903930131004

Test Set Accuracy
0.4139650872817955

Confusion matrix
[[ 13  14  51]
 [ 20  36  85]
 [ 25  40 117]]

Classification report
              precision    recall  f1-score   support

    negative       0.22      0.17      0.19        78
     neutral       0.40      0.26      0.31       141
    positive       0.46      0.64      0.54       182

    accuracy                           0.41       401
   macro avg       0.36      0.35      0.35       401
weighted avg       0.39      0.41      0.39       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.7205240174672489

Test Set Accuracy
0.4014962593516209

Confusion matrix
[[ 15  21  44]
 [ 29  31  79]
 [ 30  37 115]]

Classification report
              precision    recall  f1-score   support

    negative       0.20      0.19      0.19        80
     neutral       0.35      0.22      0.27       139
    positive       0.48      0.63      0.55       182

    accuracy                           0.40       401
   macro avg       0.34      0.35      0.34       401
weighted avg       0.38      0.40      0.38       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.7348721147847785

Test Set Accuracy
0.40648379052369077

Confusion matrix
[[ 12  22  38]
 [ 15  49  83]
 [ 24  56 102]]

Classification report
              precision    recall  f1-score   support

    negative       0.24      0.17      0.20        72
     neutral       0.39      0.33      0.36       147
    positive       0.46      0.56      0.50       182

    accuracy                           0.41       401
   macro avg       0.36      0.35      0.35       401
weighted avg       0.39      0.41      0.39       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.7117903930131004

Test Set Accuracy
0.42643391521197005

Confusion matrix
[[ 10  18  43]
 [ 15  30  98]
 [ 31  25 131]]

Classification report
              precision    recall  f1-score   support

    negative       0.18      0.14      0.16        71
     neutral       0.41      0.21      0.28       143
    positive       0.48      0.70      0.57       187

    accuracy                           0.43       401
   macro avg       0.36      0.35      0.34       401
weighted avg       0.40      0.43      0.39       401


5-fold cross-validated Accuracy: 0.40648379052369077

5-fold cross-validated F1 score: 0.33987160598254124

Pipeline(memory=None,
         steps=[('vectorizer',
                 TfidfVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.float64'>,
                                 encoding='utf-8', input='content',
                                 lowercase=True, max_df=1.0, max_features=None,
                                 min_df=1, ngram_range=(1, 2), norm='l2',
                                 preprocessor=None, smooth_idf=True,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be...
                 SelectKBest(k=300,
                             score_func=<function chi2 at 0x00000237811AE158>)),
                ('clf',
                 OneVsRestClassifier(estimator=SVC(C=1.0, break_ties=False,
                                                   cache_size=200,
                                                   class_weight='balanced',
                                                   coef0=0.0,
                                                   decision_function_shape='ovr',
                                                   degree=3, gamma='scale',
                                                   kernel='rbf', max_iter=-1,
                                                   probability=True,
                                                   random_state=42,
                                                   shrinking=True, tol=0.001,
                                                   verbose=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.4597629444791017

Test Set Accuracy
0.3341645885286783

Confusion matrix
[[  3  67   0]
 [ 12 131   0]
 [ 15 173   0]]

Classification report
              precision    recall  f1-score   support

    negative       0.10      0.04      0.06        70
     neutral       0.35      0.92      0.51       143
    positive       0.00      0.00      0.00       188

    accuracy                           0.33       401
   macro avg       0.15      0.32      0.19       401
weighted avg       0.14      0.33      0.19       401


Training set shape: (1603,)

Test set shape: (401,)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.5433562071116657

Test Set Accuracy
0.42643391521197005

Confusion matrix
[[  5   0  73]
 [  5   0 136]
 [ 16   0 166]]

Classification report
              precision    recall  f1-score   support

    negative       0.19      0.06      0.10        78
     neutral       0.00      0.00      0.00       141
    positive       0.44      0.91      0.60       182

    accuracy                           0.43       401
   macro avg       0.21      0.33      0.23       401
weighted avg       0.24      0.43      0.29       401


C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.4279475982532751

Test Set Accuracy
0.32917705735660846

Confusion matrix
[[ 10  70   0]
 [ 17 122   0]
 [ 13 169   0]]

Classification report
              precision    recall  f1-score   support

    negative       0.25      0.12      0.17        80
     neutral       0.34      0.88      0.49       139
    positive       0.00      0.00      0.00       182

    accuracy                           0.33       401
   macro avg       0.20      0.33      0.22       401
weighted avg       0.17      0.33      0.20       401


Training set shape: (1603,)

Test set shape: (401,)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.438552713661884

Test Set Accuracy
0.34663341645885287

Confusion matrix
[[  2  70   0]
 [ 10 137   0]
 [ 13 169   0]]

Classification report
              precision    recall  f1-score   support

    negative       0.08      0.03      0.04        72
     neutral       0.36      0.93      0.52       147
    positive       0.00      0.00      0.00       182

    accuracy                           0.35       401
   macro avg       0.15      0.32      0.19       401
weighted avg       0.15      0.35      0.20       401


C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5676855895196506

Test Set Accuracy
0.4463840399002494

Confusion matrix
[[  8   0  63]
 [  8   0 135]
 [ 16   0 171]]

Classification report
              precision    recall  f1-score   support

    negative       0.25      0.11      0.16        71
     neutral       0.00      0.00      0.00       143
    positive       0.46      0.91      0.62       187

    accuracy                           0.45       401
   macro avg       0.24      0.34      0.26       401
weighted avg       0.26      0.45      0.31       401


5-fold cross-validated Accuracy: 0.37655860349127185

5-fold cross-validated F1 score: 0.21681225433930754

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Pipeline(memory=None,
         steps=[('vectorizer',
                 CountVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.int64'>, encoding='utf-8',
                                 input='content', lowercase=True, max_df=1.0,
                                 max_features=None, min_df=1,
                                 ngram_range=(1, 2), preprocessor=None,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be', 'a',
                                             'and', 'any', 'be', 'a', '...
                                                                      ccp_alpha=0.0,
                                                                      class_weight='balanced',
                                                                      criterion='gini',
                                                                      max_depth=3,
                                                                      max_features='auto',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_impurity_split=None,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=4,
                                                                      oob_score=False,
                                                                      random_state=42,
                                                                      verbose=0,
                                                                      warm_start=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6257018091079226

Test Set Accuracy
0.4014962593516209

Confusion matrix
[[  6  21  43]
 [ 14  45  84]
 [ 28  50 110]]

Classification report
              precision    recall  f1-score   support

    negative       0.12      0.09      0.10        70
     neutral       0.39      0.31      0.35       143
    positive       0.46      0.59      0.52       188

    accuracy                           0.40       401
   macro avg       0.33      0.33      0.32       401
weighted avg       0.38      0.40      0.38       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5926388022457891

Test Set Accuracy
0.44139650872817954

Confusion matrix
[[ 18  14  46]
 [ 20  38  83]
 [ 20  41 121]]

Classification report
              precision    recall  f1-score   support

    negative       0.31      0.23      0.26        78
     neutral       0.41      0.27      0.32       141
    positive       0.48      0.66      0.56       182

    accuracy                           0.44       401
   macro avg       0.40      0.39      0.38       401
weighted avg       0.42      0.44      0.42       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5907673112913288

Test Set Accuracy
0.40399002493765584

Confusion matrix
[[  9  21  50]
 [ 31  25  83]
 [ 28  26 128]]

Classification report
              precision    recall  f1-score   support

    negative       0.13      0.11      0.12        80
     neutral       0.35      0.18      0.24       139
    positive       0.49      0.70      0.58       182

    accuracy                           0.40       401
   macro avg       0.32      0.33      0.31       401
weighted avg       0.37      0.40      0.37       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6013724266999376

Test Set Accuracy
0.3940149625935162

Confusion matrix
[[  7  17  48]
 [ 14  37  96]
 [ 19  49 114]]

Classification report
              precision    recall  f1-score   support

    negative       0.17      0.10      0.12        72
     neutral       0.36      0.25      0.30       147
    positive       0.44      0.63      0.52       182

    accuracy                           0.39       401
   macro avg       0.33      0.33      0.31       401
weighted avg       0.36      0.39      0.37       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6026200873362445

Test Set Accuracy
0.4513715710723192

Confusion matrix
[[  8  14  49]
 [ 13  26 104]
 [ 17  23 147]]

Classification report
              precision    recall  f1-score   support

    negative       0.21      0.11      0.15        71
     neutral       0.41      0.18      0.25       143
    positive       0.49      0.79      0.60       187

    accuracy                           0.45       401
   macro avg       0.37      0.36      0.33       401
weighted avg       0.41      0.45      0.40       401


5-fold cross-validated Accuracy: 0.4184538653366583

5-fold cross-validated F1 score: 0.33300469040215747

Pipeline(memory=None,
         steps=[('vectorizer',
                 TfidfVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.float64'>,
                                 encoding='utf-8', input='content',
                                 lowercase=True, max_df=1.0, max_features=None,
                                 min_df=1, ngram_range=(1, 2), norm='l2',
                                 preprocessor=None, smooth_idf=True,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be...
                                                                      ccp_alpha=0.0,
                                                                      class_weight='balanced',
                                                                      criterion='gini',
                                                                      max_depth=3,
                                                                      max_features='auto',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_impurity_split=None,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=4,
                                                                      oob_score=False,
                                                                      random_state=42,
                                                                      verbose=0,
                                                                      warm_start=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5383655645664379

Test Set Accuracy
0.4488778054862843

Confusion matrix
[[  2   0  68]
 [  9   0 134]
 [ 10   0 178]]

Classification report
              precision    recall  f1-score   support

    negative       0.10      0.03      0.04        70
     neutral       0.00      0.00      0.00       143
    positive       0.47      0.95      0.63       188

    accuracy                           0.45       401
   macro avg       0.19      0.33      0.22       401
weighted avg       0.24      0.45      0.30       401


Training set shape: (1603,)

Test set shape: (401,)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.529008109794136

Test Set Accuracy
0.4339152119700748

Confusion matrix
[[  4   1  73]
 [  2   0 139]
 [ 10   2 170]]

Classification report
              precision    recall  f1-score   support

    negative       0.25      0.05      0.09        78
     neutral       0.00      0.00      0.00       141
    positive       0.45      0.93      0.60       182

    accuracy                           0.43       401
   macro avg       0.23      0.33      0.23       401
weighted avg       0.25      0.43      0.29       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5152838427947598

Test Set Accuracy
0.4538653366583541

Confusion matrix
[[  7   0  73]
 [ 10   0 129]
 [  7   0 175]]

Classification report
C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

    negative       0.29      0.09      0.13        80
     neutral       0.00      0.00      0.00       139
    positive       0.46      0.96      0.63       182

    accuracy                           0.45       401
   macro avg       0.25      0.35      0.25       401
weighted avg       0.27      0.45      0.31       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5134123518402994

Test Set Accuracy
0.4314214463840399

Confusion matrix
[[  2   0  70]
 [  6   1 140]
 [ 12   0 170]]

Classification report
              precision    recall  f1-score   support

    negative       0.10      0.03      0.04        72
     neutral       1.00      0.01      0.01       147
    positive       0.45      0.93      0.60       182

    accuracy                           0.43       401
   macro avg       0.52      0.32      0.22       401
weighted avg       0.59      0.43      0.29       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.537117903930131

Test Set Accuracy
0.4538653366583541

Confusion matrix
[[  6   1  64]
 [  5   0 138]
 [ 11   0 176]]

Classification report
              precision    recall  f1-score   support

    negative       0.27      0.08      0.13        71
     neutral       0.00      0.00      0.00       143
    positive       0.47      0.94      0.62       187

    accuracy                           0.45       401
   macro avg       0.25      0.34      0.25       401
weighted avg       0.27      0.45      0.31       401


5-fold cross-validated Accuracy: 0.44438902743142145

5-fold cross-validated F1 score: 0.23556056071682682

Pipeline(memory=None,
         steps=[('vectorizer',
                 CountVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.int64'>, encoding='utf-8',
                                 input='content', lowercase=True, max_df=1.0,
                                 max_features=None, min_df=1,
                                 ngram_range=(1, 2), preprocessor=None,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be', 'a',
                                             'and', 'any', 'be', 'a', '...
                                                             booster='gbtree',
                                                             colsample_bylevel=1,
                                                             colsample_bynode=1,
                                                             colsample_bytree=1,
                                                             gamma=0,
                                                             learning_rate=0.1,
                                                             max_delta_step=0,
                                                             max_depth=3,
                                                             min_child_weight=1,
                                                             missing=None,
                                                             n_estimators=100,
                                                             n_jobs=4,
                                                             nthread=None,
                                                             objective='binary:logistic',
                                                             random_state=42,
                                                             reg_alpha=0,
                                                             reg_lambda=1,
                                                             scale_pos_weight=1,
                                                             seed=None,
                                                             silent=None,
                                                             subsample=1,
                                                             verbosity=1),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5714285714285714

Test Set Accuracy
0.456359102244389

Confusion matrix
[[  1  14  55]
 [  2  27 114]
 [  3  30 155]]

Classification report
              precision    recall  f1-score   support

    negative       0.17      0.01      0.03        70
     neutral       0.38      0.19      0.25       143
    positive       0.48      0.82      0.61       188

    accuracy                           0.46       401
   macro avg       0.34      0.34      0.29       401
weighted avg       0.39      0.46      0.38       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5545851528384279

Test Set Accuracy
0.44389027431421446

Confusion matrix
[[  5   4  69]
 [  6  19 116]
 [  5  23 154]]

Classification report
              precision    recall  f1-score   support

    negative       0.31      0.06      0.11        78
     neutral       0.41      0.13      0.20       141
    positive       0.45      0.85      0.59       182

    accuracy                           0.44       401
   macro avg       0.39      0.35      0.30       401
weighted avg       0.41      0.44      0.36       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5601996257018091

Test Set Accuracy
0.44139650872817954

Confusion matrix
[[  2  19  59]
 [  2  23 114]
 [  5  25 152]]

Classification report
              precision    recall  f1-score   support

    negative       0.22      0.03      0.04        80
     neutral       0.34      0.17      0.22       139
    positive       0.47      0.84      0.60       182

    accuracy                           0.44       401
   macro avg       0.34      0.34      0.29       401
weighted avg       0.38      0.44      0.36       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.578914535246413

Test Set Accuracy
0.43640897755610975

Confusion matrix
[[  1  15  56]
 [  2  31 114]
 [  6  33 143]]

Classification report
              precision    recall  f1-score   support

    negative       0.11      0.01      0.02        72
     neutral       0.39      0.21      0.27       147
    positive       0.46      0.79      0.58       182

    accuracy                           0.44       401
   macro avg       0.32      0.34      0.29       401
weighted avg       0.37      0.44      0.37       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5639426076107299

Test Set Accuracy
0.4713216957605985

Confusion matrix
[[  0  10  61]
 [  1  17 125]
 [  1  14 172]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        71
     neutral       0.41      0.12      0.18       143
    positive       0.48      0.92      0.63       187

    accuracy                           0.47       401
   macro avg       0.30      0.35      0.27       401
weighted avg       0.37      0.47      0.36       401


5-fold cross-validated Accuracy: 0.4498753117206983

5-fold cross-validated F1 score: 0.28970095668641443

Pipeline(memory=None,
         steps=[('vectorizer',
                 TfidfVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.float64'>,
                                 encoding='utf-8', input='content',
                                 lowercase=True, max_df=1.0, max_features=None,
                                 min_df=1, ngram_range=(1, 2), norm='l2',
                                 preprocessor=None, smooth_idf=True,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be...
                                                             booster='gbtree',
                                                             colsample_bylevel=1,
                                                             colsample_bynode=1,
                                                             colsample_bytree=1,
                                                             gamma=0,
                                                             learning_rate=0.1,
                                                             max_delta_step=0,
                                                             max_depth=3,
                                                             min_child_weight=1,
                                                             missing=None,
                                                             n_estimators=100,
                                                             n_jobs=4,
                                                             nthread=None,
                                                             objective='binary:logistic',
                                                             random_state=42,
                                                             reg_alpha=0,
                                                             reg_lambda=1,
                                                             scale_pos_weight=1,
                                                             seed=None,
                                                             silent=None,
                                                             subsample=1,
                                                             verbosity=1),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.4672489082969432

Test Set Accuracy
0.4688279301745636

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Confusion matrix
[[  0   0  70]
 [  0   0 143]
 [  0   0 188]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        70
     neutral       0.00      0.00      0.00       143
    positive       0.47      1.00      0.64       188

    accuracy                           0.47       401
   macro avg       0.16      0.33      0.21       401
weighted avg       0.22      0.47      0.30       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.45726762320648784

Test Set Accuracy
0.4538653366583541

Confusion matrix
[[  1   0  77]
 [  0   0 141]
 [  1   0 181]]

Classification report
C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

    negative       0.50      0.01      0.03        78
     neutral       0.00      0.00      0.00       141
    positive       0.45      0.99      0.62       182

    accuracy                           0.45       401
   macro avg       0.32      0.34      0.22       401
weighted avg       0.30      0.45      0.29       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.4647535870243294

Test Set Accuracy
0.4538653366583541

Confusion matrix
[[  1   0  79]
 [  4   0 135]
 [  1   0 181]]

Classification report
              precision    recall  f1-score   support

    negative       0.17      0.01      0.02        80
     neutral       0.00      0.00      0.00       139
    positive       0.46      0.99      0.63       182

    accuracy                           0.45       401
   macro avg       0.21      0.34      0.22       401
weighted avg       0.24      0.45      0.29       401


Training set shape: (1603,)

Test set shape: (401,)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.4578914535246413

Test Set Accuracy
0.4463840399002494

Confusion matrix
[[  1   0  71]
 [  2   0 145]
 [  4   0 178]]

Classification report
              precision    recall  f1-score   support

    negative       0.14      0.01      0.03        72
     neutral       0.00      0.00      0.00       147
    positive       0.45      0.98      0.62       182

    accuracy                           0.45       401
   macro avg       0.20      0.33      0.21       401
weighted avg       0.23      0.45      0.29       401


C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.47473487211478477

Test Set Accuracy
0.46384039900249374

Confusion matrix
[[  0   0  71]
 [  1   0 142]
 [  1   0 186]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        71
     neutral       0.00      0.00      0.00       143
    positive       0.47      0.99      0.63       187

    accuracy                           0.46       401
   macro avg       0.16      0.33      0.21       401
weighted avg       0.22      0.46      0.30       401


5-fold cross-validated Accuracy: 0.45735660847880305

5-fold cross-validated F1 score: 0.2143504619761823

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Pipeline(memory=None,
         steps=[('vectorizer',
                 CountVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.int64'>, encoding='utf-8',
                                 input='content', lowercase=True, max_df=1.0,
                                 max_features=None, min_df=1,
                                 ngram_range=(1, 2), preprocessor=None,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be', 'a',
                                             'and', 'any', 'be', 'a', '...
                             score_func=<function chi2 at 0x00000237811AE158>)),
                ('clf',
                 OneVsRestClassifier(estimator=LogisticRegression(C=1.0,
                                                                  class_weight='balanced',
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=5000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=42,
                                                                  solver='liblinear',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6724890829694323

Test Set Accuracy
0.39900249376558605

Confusion matrix
[[ 10  21  39]
 [ 18  47  78]
 [ 38  47 103]]

Classification report
              precision    recall  f1-score   support

    negative       0.15      0.14      0.15        70
     neutral       0.41      0.33      0.36       143
    positive       0.47      0.55      0.50       188

    accuracy                           0.40       401
   macro avg       0.34      0.34      0.34       401
weighted avg       0.39      0.40      0.39       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.653150343106675

Test Set Accuracy
0.39900249376558605

Confusion matrix
[[ 23  12  43]
 [ 35  31  75]
 [ 36  40 106]]

Classification report
              precision    recall  f1-score   support

    negative       0.24      0.29      0.27        78
     neutral       0.37      0.22      0.28       141
    positive       0.47      0.58      0.52       182

    accuracy                           0.40       401
   macro avg       0.36      0.37      0.36       401
weighted avg       0.39      0.40      0.39       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6581409856519027

Test Set Accuracy
0.3940149625935162

Confusion matrix
[[ 15  21  44]
 [ 34  32  73]
 [ 33  38 111]]

Classification report
              precision    recall  f1-score   support

    negative       0.18      0.19      0.19        80
     neutral       0.35      0.23      0.28       139
    positive       0.49      0.61      0.54       182

    accuracy                           0.39       401
   macro avg       0.34      0.34      0.33       401
weighted avg       0.38      0.39      0.38       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.6637554585152838

Test Set Accuracy
0.3740648379052369

Confusion matrix
[[11 30 31]
 [24 48 75]
 [30 61 91]]

Classification report
              precision    recall  f1-score   support

    negative       0.17      0.15      0.16        72
     neutral       0.35      0.33      0.34       147
    positive       0.46      0.50      0.48       182

    accuracy                           0.37       401
   macro avg       0.33      0.33      0.33       401
weighted avg       0.37      0.37      0.37       401


Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.653150343106675

Test Set Accuracy
0.4314214463840399

Confusion matrix
[[ 12  20  39]
 [ 22  30  91]
 [ 33  23 131]]

Classification report
              precision    recall  f1-score   support

    negative       0.18      0.17      0.17        71
     neutral       0.41      0.21      0.28       143
    positive       0.50      0.70      0.58       187

    accuracy                           0.43       401
   macro avg       0.36      0.36      0.35       401
weighted avg       0.41      0.43      0.40       401


5-fold cross-validated Accuracy: 0.39950124688279304

5-fold cross-validated F1 score: 0.3400385340197993

Pipeline(memory=None,
         steps=[('vectorizer',
                 TfidfVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.float64'>,
                                 encoding='utf-8', input='content',
                                 lowercase=True, max_df=1.0, max_features=None,
                                 min_df=1, ngram_range=(1, 2), norm='l2',
                                 preprocessor=None, smooth_idf=True,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be...
                             score_func=<function chi2 at 0x00000237811AE158>)),
                ('clf',
                 OneVsRestClassifier(estimator=LogisticRegression(C=1.0,
                                                                  class_weight='balanced',
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=5000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=42,
                                                                  solver='liblinear',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5689332501559575

Test Set Accuracy
0.4389027431421446

Confusion matrix
[[  3   0  67]
 [ 12   0 131]
 [ 15   0 173]]

Classification report
              precision    recall  f1-score   support

    negative       0.10      0.04      0.06        70
     neutral       0.00      0.00      0.00       143
    positive       0.47      0.92      0.62       188

    accuracy                           0.44       401
   macro avg       0.19      0.32      0.23       401
weighted avg       0.24      0.44      0.30       401


Training set shape: (1603,)

Test set shape: (401,)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.5433562071116657

Test Set Accuracy
0.428927680798005

Confusion matrix
[[  5   0  73]
 [  5   0 136]
 [ 15   0 167]]

Classification report
              precision    recall  f1-score   support

    negative       0.20      0.06      0.10        78
     neutral       0.00      0.00      0.00       141
    positive       0.44      0.92      0.60       182

    accuracy                           0.43       401
   macro avg       0.21      0.33      0.23       401
weighted avg       0.24      0.43      0.29       401


Training set shape: (1603,)

Test set shape: (401,)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.5327510917030568

Test Set Accuracy
0.4463840399002494

Confusion matrix
[[ 10   0  70]
 [ 18   0 121]
 [ 13   0 169]]

Classification report
              precision    recall  f1-score   support

    negative       0.24      0.12      0.17        80
     neutral       0.00      0.00      0.00       139
    positive       0.47      0.93      0.62       182

    accuracy                           0.45       401
   macro avg       0.24      0.35      0.26       401
weighted avg       0.26      0.45      0.32       401


C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training set shape: (1603,)

Test set shape: (401,)

Training Set Accuracy
0.5265127885215222

Test Set Accuracy
0.42643391521197005

Confusion matrix
[[  2   0  70]
 [ 10   0 137]
 [ 13   0 169]]

Classification report
              precision    recall  f1-score   support

    negative       0.08      0.03      0.04        72
     neutral       0.00      0.00      0.00       147
    positive       0.45      0.93      0.61       182

    accuracy                           0.43       401
   macro avg       0.18      0.32      0.22       401
weighted avg       0.22      0.43      0.28       401


Training set shape: (1603,)

Test set shape: (401,)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.5664379288833438

Test Set Accuracy
0.4463840399002494

Confusion matrix
[[  8   0  63]
 [  8   0 135]
 [ 16   0 171]]

Classification report
              precision    recall  f1-score   support

    negative       0.25      0.11      0.16        71
     neutral       0.00      0.00      0.00       143
    positive       0.46      0.91      0.62       187

    accuracy                           0.45       401
   macro avg       0.24      0.34      0.26       401
weighted avg       0.26      0.45      0.31       401


5-fold cross-validated Accuracy: 0.43740648379052366

5-fold cross-validated F1 score: 0.23872941413883955

Instantiated list of models with numeric features!

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
DataFrame shape: (2004, 10)

DataFrame head:                                               text_feat  ...  sentiment_label
7809  Lisa Page Ex Lawyer Whose Texts Criticized Tru...  ...          neutral
5590  This Mexican Chef Is Having a Very Good Year G...  ...          neutral
3329  Why be Democrats Talking About Impeachment Bec...  ...         positive
1728  Democratic Presidential Hopeful Klobuchar Sets...  ...          neutral
9926  Jeffrey Epstein Gun Control Simone Biles Your ...  ...          neutral

[5 rows x 10 columns]

DataFrame labels; positive    937
neutral     717
negative    350
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
1922   Elizabeth Warren Wants to Cancel Student Loans...  ...          neutral
10223  Trump Presses His Argument of a Border Crisis ...  ...          neutral
8313   Big Business Says It Will Tackle Climate Chang...  ...          neutral
2055   Unable to Post Bail You Will Pay for That for ...  ...         negative
1951   Eliminating Child Poverty With a Government Ch...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    908
neutral     703
negative    393
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
10432  The Impeachment Questions We Were Afraid to As...  ...         positive
1304   Who Won the Debate Experts Weigh In There be l...  ...         positive
9176   Years Later Native American Tribe in Montana G...  ...          neutral
2669   In a Collection of Tributes the Gang Is All He...  ...         positive
8691   Trial date be set for Lev Parnas Parnas have s...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    907
neutral     697
negative    400
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                               text_feat  ...  sentiment_label
5266  How Can You Put Life of Onstage With Puppets I...  ...          neutral
1432  Momentum for Harris Big Haul for Buttigieg Thi...  ...         negative
1515  Should College Be Free The Democratic Party be...  ...          neutral
7793  Trump Possible Policy Shift on the Taliban A r...  ...         positive
5133  You Oughta The Road to Making a Anthem a Broad...  ...          neutral

[5 rows x 10 columns]

DataFrame labels; positive    910
neutral     733
negative    361
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
7242   Impeachment Briefing What Happened Today Anoth...  ...         positive
10153  Wartime Secrets and Intrigue From the Hotel Ri...  ...         positive
4061   Joe Biden and the Apologies That be Politician...  ...         negative
6344   Elizabeth Warren Has a Poet on Her Team Here W...  ...          neutral
10739  Trump Wants a Fight Pelosi Can Hit Back With r...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    935
neutral     715
negative    354
Name: sentiment_label, dtype: int64

Split DataFrames into 5-Fold datasets!

Starting Model Training!

Pipeline(memory=None,
         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),
                ('clf',
                 OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0,
                                                             class_prior=None,
                                                             fit_prior=True),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.5583281347473488

Test Set Accuracy
0.5685785536159601

Confusion matrix
[[  0   0  70]
 [  0  41 102]
 [  0   1 187]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        70
     neutral       0.98      0.29      0.44       143
    positive       0.52      0.99      0.68       188

    accuracy                           0.57       401
   macro avg       0.50      0.43      0.38       401
weighted avg       0.59      0.57      0.48       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.5514660012476607

Test Set Accuracy
0.5536159600997507

Confusion matrix
[[  0   2  76]
 [  0  41 100]
 [  0   1 181]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        78
     neutral       0.93      0.29      0.44       141
    positive       0.51      0.99      0.67       182

    accuracy                           0.55       401
   macro avg       0.48      0.43      0.37       401
weighted avg       0.56      0.55      0.46       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.5302557704304429

Test Set Accuracy
0.5236907730673317

Confusion matrix
[[  0   4  76]
 [  0  32 107]
 [  0   4 178]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        80
     neutral       0.80      0.23      0.36       139
    positive       0.49      0.98      0.66       182

    accuracy                           0.52       401
   macro avg       0.43      0.40      0.34       401
weighted avg       0.50      0.52      0.42       401


C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.5963817841547099

Test Set Accuracy
0.6184538653366584

Confusion matrix
[[  0   2  70]
 [  0  68  79]
 [  0   2 180]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        72
     neutral       0.94      0.46      0.62       147
    positive       0.55      0.99      0.70       182

    accuracy                           0.62       401
   macro avg       0.50      0.48      0.44       401
weighted avg       0.59      0.62      0.55       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training Set Accuracy
0.5539613225202745

Test Set Accuracy
0.5386533665835411

Confusion matrix
[[  0   1  70]
 [  0  29 114]
 [  0   0 187]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        71
     neutral       0.97      0.20      0.34       143
    positive       0.50      1.00      0.67       187

    accuracy                           0.54       401
   macro avg       0.49      0.40      0.34       401
weighted avg       0.58      0.54      0.43       401


5-fold cross-validated Accuracy: 0.5605985037406483

5-fold cross-validated F1 score: 0.37240036124289483

Pipeline(memory=None,
         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),
                ('clf',
                 OneVsRestClassifier(estimator=SVC(C=1.0, break_ties=False,
                                                   cache_size=200,
                                                   class_weight='balanced',
                                                   coef0=0.0,
                                                   decision_function_shape='ovr',
                                                   degree=3, gamma='scale',
                                                   kernel='rbf', max_iter=-1,
                                                   probability=True,
                                                   random_state=42,
                                                   shrinking=True, tol=0.001,
                                                   verbose=False),
                                     n_jobs=None))],
         verbose=False)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6494073611977542

Test Set Accuracy
0.6259351620947631

Confusion matrix
[[ 17  13  40]
 [ 14 107  22]
 [ 43  18 127]]

Classification report
              precision    recall  f1-score   support

    negative       0.23      0.24      0.24        70
     neutral       0.78      0.75      0.76       143
    positive       0.67      0.68      0.67       188

    accuracy                           0.63       401
   macro avg       0.56      0.56      0.56       401
weighted avg       0.63      0.63      0.63       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6325639426076107

Test Set Accuracy
0.5536159600997507

Confusion matrix
[[ 18  19  41]
 [ 11  93  37]
 [ 58  13 111]]

Classification report
              precision    recall  f1-score   support

    negative       0.21      0.23      0.22        78
     neutral       0.74      0.66      0.70       141
    positive       0.59      0.61      0.60       182

    accuracy                           0.55       401
   macro avg       0.51      0.50      0.51       401
weighted avg       0.57      0.55      0.56       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6325639426076107

Test Set Accuracy
0.5985037406483791

Confusion matrix
[[ 17  13  50]
 [ 11  86  42]
 [ 31  14 137]]

Classification report
              precision    recall  f1-score   support

    negative       0.29      0.21      0.24        80
     neutral       0.76      0.62      0.68       139
    positive       0.60      0.75      0.67       182

    accuracy                           0.60       401
   macro avg       0.55      0.53      0.53       401
weighted avg       0.59      0.60      0.59       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6381784154709919

Test Set Accuracy
0.600997506234414

Confusion matrix
[[ 18   8  46]
 [ 20 100  27]
 [ 51   8 123]]

Classification report
              precision    recall  f1-score   support

    negative       0.20      0.25      0.22        72
     neutral       0.86      0.68      0.76       147
    positive       0.63      0.68      0.65       182

    accuracy                           0.60       401
   macro avg       0.56      0.54      0.54       401
weighted avg       0.64      0.60      0.61       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6412975670617592

Test Set Accuracy
0.5311720698254364

Confusion matrix
[[ 15  11  45]
 [ 21  90  32]
 [ 67  12 108]]

Classification report
              precision    recall  f1-score   support

    negative       0.15      0.21      0.17        71
     neutral       0.80      0.63      0.70       143
    positive       0.58      0.58      0.58       187

    accuracy                           0.53       401
   macro avg       0.51      0.47      0.49       401
weighted avg       0.58      0.53      0.55       401


5-fold cross-validated Accuracy: 0.5820448877805486

5-fold cross-validated F1 score: 0.5248051144964

Pipeline(memory=None,
         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),
                ('clf',
                 OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True,
                                                                      ccp_alpha=0.0,
                                                                      class_weight='balanced',
                                                                      criterion='gini',
                                                                      max_depth=3,
                                                                      max_features='auto',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_impurity_split=None,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=4,
                                                                      oob_score=False,
                                                                      random_state=42,
                                                                      verbose=0,
                                                                      warm_start=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6812227074235808

Test Set Accuracy
0.6683291770573566

Confusion matrix
[[  5  10  55]
 [  9 102  32]
 [ 16  11 161]]

Classification report
              precision    recall  f1-score   support

    negative       0.17      0.07      0.10        70
     neutral       0.83      0.71      0.77       143
    positive       0.65      0.86      0.74       188

    accuracy                           0.67       401
   macro avg       0.55      0.55      0.54       401
weighted avg       0.63      0.67      0.64       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6793512164691204

Test Set Accuracy
0.6259351620947631

Confusion matrix
[[  3  12  63]
 [  7  87  47]
 [ 17   4 161]]

Classification report
              precision    recall  f1-score   support

    negative       0.11      0.04      0.06        78
     neutral       0.84      0.62      0.71       141
    positive       0.59      0.88      0.71       182

    accuracy                           0.63       401
   macro avg       0.52      0.51      0.49       401
weighted avg       0.59      0.63      0.58       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6731129132875858

Test Set Accuracy
0.6059850374064838

Confusion matrix
[[ 17   9  54]
 [ 13  77  49]
 [ 24   9 149]]

Classification report
              precision    recall  f1-score   support

    negative       0.31      0.21      0.25        80
     neutral       0.81      0.55      0.66       139
    positive       0.59      0.82      0.69       182

    accuracy                           0.61       401
   macro avg       0.57      0.53      0.53       401
weighted avg       0.61      0.61      0.59       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6762320648783531

Test Set Accuracy
0.6608478802992519

Confusion matrix
[[  8   3  61]
 [  9  95  43]
 [ 17   3 162]]

Classification report
              precision    recall  f1-score   support

    negative       0.24      0.11      0.15        72
     neutral       0.94      0.65      0.77       147
    positive       0.61      0.89      0.72       182

    accuracy                           0.66       401
   macro avg       0.59      0.55      0.55       401
weighted avg       0.66      0.66      0.64       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6712414223331253

Test Set Accuracy
0.5910224438902744

Confusion matrix
[[ 14   6  51]
 [ 18  79  46]
 [ 40   3 144]]

Classification report
              precision    recall  f1-score   support

    negative       0.19      0.20      0.20        71
     neutral       0.90      0.55      0.68       143
    positive       0.60      0.77      0.67       187

    accuracy                           0.59       401
   macro avg       0.56      0.51      0.52       401
weighted avg       0.63      0.59      0.59       401


5-fold cross-validated Accuracy: 0.6304239401496259

5-fold cross-validated F1 score: 0.525198768530601

Pipeline(memory=None,
         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),
                ('clf',
                 OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5,
                                                             booster='gbtree',
                                                             colsample_bylevel=1,
                                                             colsample_bynode=1,
                                                             colsample_bytree=1,
                                                             gamma=0,
                                                             learning_rate=0.1,
                                                             max_delta_step=0,
                                                             max_depth=3,
                                                             min_child_weight=1,
                                                             missing=None,
                                                             n_estimators=100,
                                                             n_jobs=4,
                                                             nthread=None,
                                                             objective='binary:logistic',
                                                             random_state=42,
                                                             reg_alpha=0,
                                                             reg_lambda=1,
                                                             scale_pos_weight=1,
                                                             seed=None,
                                                             silent=None,
                                                             subsample=1,
                                                             verbosity=1),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.7205240174672489

Test Set Accuracy
0.6957605985037406

Confusion matrix
[[  0   9  61]
 [  4 108  31]
 [  4  13 171]]

Classification report
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00        70
     neutral       0.83      0.76      0.79       143
    positive       0.65      0.91      0.76       188

    accuracy                           0.70       401
   macro avg       0.49      0.55      0.52       401
weighted avg       0.60      0.70      0.64       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.7161572052401747

Test Set Accuracy
0.6508728179551122

Confusion matrix
[[  1  13  64]
 [  1  87  53]
 [  2   7 173]]

Classification report
              precision    recall  f1-score   support

    negative       0.25      0.01      0.02        78
     neutral       0.81      0.62      0.70       141
    positive       0.60      0.95      0.73       182

    accuracy                           0.65       401
   macro avg       0.55      0.53      0.49       401
weighted avg       0.61      0.65      0.58       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.7186525265127885

Test Set Accuracy
0.6259351620947631

Confusion matrix
[[  4   9  67]
 [  1  79  59]
 [  3  11 168]]

Classification report
              precision    recall  f1-score   support

    negative       0.50      0.05      0.09        80
     neutral       0.80      0.57      0.66       139
    positive       0.57      0.92      0.71       182

    accuracy                           0.63       401
   macro avg       0.62      0.51      0.49       401
weighted avg       0.64      0.63      0.57       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.7074235807860262

Test Set Accuracy
0.6807980049875312

Confusion matrix
[[  2   6  64]
 [  1 100  46]
 [  3   8 171]]

Classification report
              precision    recall  f1-score   support

    negative       0.33      0.03      0.05        72
     neutral       0.88      0.68      0.77       147
    positive       0.61      0.94      0.74       182

    accuracy                           0.68       401
   macro avg       0.61      0.55      0.52       401
weighted avg       0.66      0.68      0.63       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.7311291328758578

Test Set Accuracy
0.6483790523690773

Confusion matrix
[[  2  10  59]
 [  5  86  52]
 [  4  11 172]]

Classification report
              precision    recall  f1-score   support

    negative       0.18      0.03      0.05        71
     neutral       0.80      0.60      0.69       143
    positive       0.61      0.92      0.73       187

    accuracy                           0.65       401
   macro avg       0.53      0.52      0.49       401
weighted avg       0.60      0.65      0.60       401


5-fold cross-validated Accuracy: 0.6603491271820449

5-fold cross-validated F1 score: 0.49961043309832304

Pipeline(memory=None,
         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),
                ('clf',
                 OneVsRestClassifier(estimator=LogisticRegression(C=100,
                                                                  class_weight='balanced',
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=5000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=42,
                                                                  solver='liblinear',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     n_jobs=None))],
         verbose=False)

Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.587024329382408

Test Set Accuracy
0.6134663341645885

Confusion matrix
[[ 10  19  41]
 [  5 120  18]
 [ 27  45 116]]

Classification report
              precision    recall  f1-score   support

    negative       0.24      0.14      0.18        70
     neutral       0.65      0.84      0.73       143
    positive       0.66      0.62      0.64       188

    accuracy                           0.61       401
   macro avg       0.52      0.53      0.52       401
weighted avg       0.58      0.61      0.59       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.6051154086088584

Test Set Accuracy
0.600997506234414

Confusion matrix
[[ 10  26  42]
 [  4 106  31]
 [ 17  40 125]]

Classification report
              precision    recall  f1-score   support

    negative       0.32      0.13      0.18        78
     neutral       0.62      0.75      0.68       141
    positive       0.63      0.69      0.66       182

    accuracy                           0.60       401
   macro avg       0.52      0.52      0.51       401
weighted avg       0.57      0.60      0.57       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.5745477230193388

Test Set Accuracy
0.5511221945137157

Confusion matrix
[[ 10  29  41]
 [ 11  97  31]
 [ 23  45 114]]

Classification report
              precision    recall  f1-score   support

    negative       0.23      0.12      0.16        80
     neutral       0.57      0.70      0.63       139
    positive       0.61      0.63      0.62       182

    accuracy                           0.55       401
   macro avg       0.47      0.48      0.47       401
weighted avg       0.52      0.55      0.53       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.5957579538365565

Test Set Accuracy
0.6159600997506235

Confusion matrix
[[  3  23  46]
 [  3 118  26]
 [ 15  41 126]]

Classification report
              precision    recall  f1-score   support

    negative       0.14      0.04      0.06        72
     neutral       0.65      0.80      0.72       147
    positive       0.64      0.69      0.66       182

    accuracy                           0.62       401
   macro avg       0.48      0.51      0.48       401
weighted avg       0.55      0.62      0.58       401


Training set shape: (1603, 8)

Test set shape: (401, 8)

Training Set Accuracy
0.5988771054273238

Test Set Accuracy
0.5511221945137157

Confusion matrix
[[  8  20  43]
 [ 10 106  27]
 [ 28  52 107]]

Classification report
              precision    recall  f1-score   support

    negative       0.17      0.11      0.14        71
     neutral       0.60      0.74      0.66       143
    positive       0.60      0.57      0.59       187

    accuracy                           0.55       401
   macro avg       0.46      0.48      0.46       401
weighted avg       0.53      0.55      0.53       401


5-fold cross-validated Accuracy: 0.5865336658354114

5-fold cross-validated F1 score: 0.48713958095716176

Fitting 5 folds for each of 25 candidates, totalling 125 fits
[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.
[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   47.9s
[Parallel(n_jobs=6)]: Done 125 out of 125 | elapsed:  3.3min finished
Best random Parameters:  {'vectorizer__ngram_range': (1, 3), 'dim_red__k': 200, 'clf__estimator__n_estimators': 300, 'clf__estimator__min_samples_leaf': 48, 'clf__estimator__max_depth': 6, 'clf__estimator__learning_rate': 0.8395973154362416, 'clf__estimator__colsample_bytree': 0.3, 'clf__estimator__booster': 'gblinear'}

Best random Score:  0.4590278255271783

{'mean_fit_time': 12     3.676434
21     3.459187
19     3.035505
16     2.633450
23     3.297987
11     3.338262
24     2.376424
1      4.077596
2      3.601934
3      3.193827
6      3.855289
0      5.307968
22    34.453189
4      3.733772
13    25.525623
7      6.798440
9      6.823538
18     4.113010
8     28.737902
5     11.471730
17     3.510869
15     4.745110
10    13.248988
20     4.892520
14     5.633541
Name: mean_fit_time, dtype: float64, 'std_fit_time': 12    0.071621
21    0.107708
19    0.099283
16    0.044094
23    0.227909
11    0.093372
24    0.185680
1     0.136013
2     0.029854
3     0.048138
6     0.086853
0     0.235980
22    3.098820
4     0.099607
13    2.839121
7     0.839035
9     0.452862
18    0.043621
8     1.009528
5     0.355011
17    0.073259
15    0.040258
10    2.024901
20    0.235582
14    0.231865
Name: std_fit_time, dtype: float64, 'mean_score_time': 12    0.252661
21    0.302955
19    0.308511
16    0.249189
23    0.309105
11    0.331525
24    0.207030
1     0.314760
2     0.315256
3     0.331822
6     0.307321
0     0.310098
22    0.258911
4     0.291546
13    0.277263
7     0.297003
9     0.266947
18    0.321010
8     0.372494
5     0.292440
17    0.333013
15    0.330533
10    0.343231
20    0.356226
14    0.400765
Name: mean_score_time, dtype: float64, 'std_score_time': 12    0.009702
21    0.028395
19    0.027512
16    0.033021
23    0.023385
11    0.053610
24    0.031291
1     0.026131
2     0.035932
3     0.017407
6     0.021204
0     0.019298
22    0.065569
4     0.015296
13    0.009541
7     0.045952
9     0.016484
18    0.018349
8     0.037705
5     0.024568
17    0.009282
15    0.015485
10    0.013576
20    0.017054
14    0.020709
Name: std_score_time, dtype: float64, 'param_vectorizer__ngram_range': 12    (2, 3)
21    (1, 3)
19    (1, 3)
16    (2, 3)
23    (1, 3)
11    (1, 3)
24    (2, 3)
1     (1, 3)
2     (1, 3)
3     (1, 3)
6     (1, 3)
0     (2, 3)
22    (2, 3)
4     (2, 3)
13    (2, 3)
7     (2, 3)
9     (2, 3)
18    (1, 3)
8     (1, 3)
5     (2, 3)
17    (1, 3)
15    (1, 3)
10    (1, 3)
20    (1, 3)
14    (1, 3)
Name: param_vectorizer__ngram_range, dtype: object, 'param_dim_red__k': 12    300
21    100
19    200
16    200
23    300
11    200
24    300
1     200
2     200
3     100
6     200
0     100
22    100
4     100
13    100
7     100
9     200
18    100
8     100
5     300
17    100
15    300
10    200
20    200
14    200
Name: param_dim_red__k, dtype: object, 'param_clf__estimator__n_estimators': 12    300
21    200
19    100
16    100
23    200
11    200
24    100
1     300
2     200
3     100
6     300
0     300
22    300
4     200
13    300
7     100
9     100
18    200
8     300
5     200
17    100
15    300
10    100
20    200
14    300
Name: param_clf__estimator__n_estimators, dtype: object, 'param_clf__estimator__min_samples_leaf': 12    55
21    38
19    50
16    39
23    52
11    30
24    46
1     48
2     52
3     50
6     57
0     39
22    40
4     23
13    35
7     45
9     35
18    39
8     56
5     45
17    52
15    26
10    28
20    58
14    28
Name: param_clf__estimator__min_samples_leaf, dtype: object, 'param_clf__estimator__max_depth': 12    10
21    10
19     3
16    20
23     3
11     6
24     3
1      6
2     10
3      3
6     10
0     20
22     6
4     10
13    10
7     10
9      6
18     3
8      3
5      3
17     6
15     3
10    20
20    10
14    10
Name: param_clf__estimator__max_depth, dtype: object, 'param_clf__estimator__learning_rate': 12    0.992617
21    0.967114
19    0.163758
16     1.56644
23     1.28591
11    0.610067
24    0.584564
1     0.839597
2     0.763087
3     0.775839
6      1.91074
0       1.6302
22    0.469799
4      1.33691
13    0.355034
7     0.763087
9     0.979866
18     1.28591
8       1.2094
5      1.48993
17     1.74497
15     1.87248
10    0.457047
20     1.87248
14    0.712081
Name: param_clf__estimator__learning_rate, dtype: object, 'param_clf__estimator__colsample_bytree': 12    0.3
21    0.3
19    0.7
16    0.3
23    0.7
11    0.7
24    0.7
1     0.3
2     0.3
3     0.7
6     0.7
0     0.7
22    0.7
4     0.3
13    0.3
7     0.7
9     0.7
18    0.7
8     0.3
5     0.3
17    0.7
15    0.3
10    0.3
20    0.3
14    0.3
Name: param_clf__estimator__colsample_bytree, dtype: object, 'param_clf__estimator__booster': 12    gblinear
21    gblinear
19    gblinear
16    gblinear
23    gblinear
11    gblinear
24    gblinear
1     gblinear
2     gblinear
3     gblinear
6     gblinear
0       gbtree
22        dart
4       gbtree
13        dart
7         dart
9         dart
18      gbtree
8         dart
5         dart
17      gbtree
15      gbtree
10        dart
20      gbtree
14      gbtree
Name: param_clf__estimator__booster, dtype: object, 'params': 12    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
21    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
19    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
16    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
23    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
11    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
24    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
1     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
2     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
3     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
6     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
0     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
22    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
4     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
13    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
7     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
9     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
18    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
8     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
5     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
17    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
15    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
10    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
20    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
14    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
Name: params, dtype: object, 'split0_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
0     0.459082
22    0.459082
4     0.458583
13    0.458583
7     0.458583
9     0.457585
18    0.453094
8     0.453593
5     0.457086
17    0.453593
15    0.453094
10    0.451597
20    0.451098
14    0.451597
Name: split0_test_score, dtype: float64, 'split1_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
0     0.452595
22    0.452595
4     0.452595
13    0.452096
7     0.452096
9     0.453094
18    0.450599
8     0.450599
5     0.452595
17    0.451098
15    0.452096
10    0.449601
20    0.449102
14    0.449102
Name: split1_test_score, dtype: float64, 'split2_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
0     0.455589
22    0.456088
4     0.456088
13    0.456088
7     0.455589
9     0.453593
18    0.457086
8     0.456587
5     0.453593
17    0.456587
15    0.455589
10    0.455090
20    0.455090
14    0.455589
Name: split2_test_score, dtype: float64, 'split3_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
0     0.455589
22    0.455589
4     0.455090
13    0.455589
7     0.455589
9     0.454591
18    0.452595
8     0.452595
5     0.452595
17    0.451597
15    0.449102
10    0.453593
20    0.451597
14    0.451597
Name: split3_test_score, dtype: float64, 'split4_test_score': 12    0.458812
21    0.458812
19    0.458812
16    0.458812
23    0.458812
11    0.458812
24    0.458812
1     0.458812
2     0.458812
3     0.458812
6     0.458812
0     0.453320
22    0.452821
4     0.453320
13    0.452821
7     0.452821
9     0.449825
18    0.454319
8     0.454319
5     0.450824
17    0.451822
15    0.453320
10    0.448827
20    0.450824
14    0.449326
Name: split4_test_score, dtype: float64, 'mean_test_score': 12    0.459028
21    0.459028
19    0.459028
16    0.459028
23    0.459028
11    0.459028
24    0.459028
1     0.459028
2     0.459028
3     0.459028
6     0.459028
0     0.455235
22    0.455235
4     0.455135
13    0.455035
7     0.454935
9     0.453738
18    0.453538
8     0.453538
5     0.453338
17    0.452939
15    0.452640
10    0.451741
20    0.451542
14    0.451442
Name: mean_test_score, dtype: float64, 'std_test_score': 12    0.000108
21    0.000108
19    0.000108
16    0.000108
23    0.000108
11    0.000108
24    0.000108
1     0.000108
2     0.000108
3     0.000108
6     0.000108
0     0.002267
22    0.002385
4     0.002123
13    0.002347
7     0.002311
9     0.002501
18    0.002141
8     0.001972
5     0.002075
17    0.002009
15    0.002106
10    0.002355
20    0.001963
14    0.002332
Name: std_test_score, dtype: float64, 'rank_test_score': 12     1
21     1
19     1
16     1
23     1
11     1
24     1
1      1
2      1
3      1
6      1
0     12
22    13
4     14
13    15
7     16
9     17
18    18
8     18
5     20
17    21
15    22
10    23
20    24
14    25
Name: rank_test_score, dtype: int32, 'split0_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
0     0.473238
22    0.472115
4     0.471366
13    0.471241
7     0.472240
9     0.478852
18    0.505178
8     0.506800
5     0.480225
17    0.509919
15    0.518653
10    0.518029
20    0.513288
14    0.521772
Name: split0_train_score, dtype: float64, 'split1_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
0     0.473238
22    0.472364
4     0.471990
13    0.471740
7     0.472489
9     0.473362
18    0.491329
8     0.491204
5     0.473113
17    0.493824
15    0.501435
10    0.500686
20    0.505802
14    0.503556
Name: split1_train_score, dtype: float64, 'split2_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
0     0.469744
22    0.468996
4     0.467623
13    0.468372
7     0.469994
9     0.471366
18    0.491828
8     0.491953
5     0.472240
17    0.493824
15    0.500312
10    0.498066
20    0.496943
14    0.501560
Name: split2_train_score, dtype: float64, 'split3_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
0     0.468621
22    0.468247
4     0.466625
13    0.467374
7     0.467498
9     0.472364
18    0.485839
8     0.485465
5     0.473737
17    0.482969
15    0.501061
10    0.492327
20    0.494323
14    0.494074
Name: split3_train_score, dtype: float64, 'split4_train_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
0     0.467939
22    0.467939
4     0.466442
13    0.467565
7     0.467315
9     0.470933
18    0.488648
8     0.488772
5     0.470185
17    0.490768
15    0.502370
10    0.493887
20    0.495135
14    0.496756
Name: split4_train_score, dtype: float64, 'mean_train_score': 12    0.459028
21    0.459028
19    0.459028
16    0.459028
23    0.459028
11    0.459028
24    0.459028
1     0.459028
2     0.459028
3     0.459028
6     0.459028
0     0.470556
22    0.469932
4     0.468809
13    0.469258
7     0.469907
9     0.473376
18    0.492564
8     0.492839
5     0.473900
17    0.494261
15    0.504766
10    0.500599
20    0.501098
14    0.503543
Name: mean_train_score, dtype: float64, 'std_train_score': 12    0.000027
21    0.000027
19    0.000027
16    0.000027
23    0.000027
11    0.000027
24    0.000027
1     0.000027
2     0.000027
3     0.000027
6     0.000027
0     0.002264
22    0.001917
4     0.002385
13    0.001860
7     0.002220
9     0.002864
18    0.006659
8     0.007339
5     0.003383
17    0.008778
15    0.006975
10    0.009205
20    0.007341
14    0.009715
Name: std_train_score, dtype: float64}

{'params': 12    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
21    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
19    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
16    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
23    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
11    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
24    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
1     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
2     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
3     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
6     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
0     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
22    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
4     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
13    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
7     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
9     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
18    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
8     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
5     {'vectorizer__ngram_range': (2, 3), 'dim_red__...
17    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
15    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
10    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
20    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
14    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
Name: params, dtype: object}

{'mean_fit_time': 12    3.676434
21    3.459187
19    3.035505
16    2.633450
23    3.297987
11    3.338262
24    2.376424
1     4.077596
2     3.601934
3     3.193827
6     3.855289
Name: mean_fit_time, dtype: float64, 'std_fit_time': 12    0.071621
21    0.107708
19    0.099283
16    0.044094
23    0.227909
11    0.093372
24    0.185680
1     0.136013
2     0.029854
3     0.048138
6     0.086853
Name: std_fit_time, dtype: float64, 'mean_score_time': 12    0.252661
21    0.302955
19    0.308511
16    0.249189
23    0.309105
11    0.331525
24    0.207030
1     0.314760
2     0.315256
3     0.331822
6     0.307321
Name: mean_score_time, dtype: float64, 'std_score_time': 12    0.009702
21    0.028395
19    0.027512
16    0.033021
23    0.023385
11    0.053610
24    0.031291
1     0.026131
2     0.035932
3     0.017407
6     0.021204
Name: std_score_time, dtype: float64, 'param_vectorizer__ngram_range': 12    (2, 3)
21    (1, 3)
19    (1, 3)
16    (2, 3)
23    (1, 3)
11    (1, 3)
24    (2, 3)
1     (1, 3)
2     (1, 3)
3     (1, 3)
6     (1, 3)
Name: param_vectorizer__ngram_range, dtype: object, 'param_dim_red__k': 12    300
21    100
19    200
16    200
23    300
11    200
24    300
1     200
2     200
3     100
6     200
Name: param_dim_red__k, dtype: object, 'param_clf__estimator__n_estimators': 12    300
21    200
19    100
16    100
23    200
11    200
24    100
1     300
2     200
3     100
6     300
Name: param_clf__estimator__n_estimators, dtype: object, 'param_clf__estimator__min_samples_leaf': 12    55
21    38
19    50
16    39
23    52
11    30
24    46
1     48
2     52
3     50
6     57
Name: param_clf__estimator__min_samples_leaf, dtype: object, 'param_clf__estimator__max_depth': 12    10
21    10
19     3
16    20
23     3
11     6
24     3
1      6
2     10
3      3
6     10
Name: param_clf__estimator__max_depth, dtype: object, 'param_clf__estimator__learning_rate': 12    0.992617
21    0.967114
19    0.163758
16     1.56644
23     1.28591
11    0.610067
24    0.584564
1     0.839597
2     0.763087
3     0.775839
6      1.91074
Name: param_clf__estimator__learning_rate, dtype: object, 'param_clf__estimator__colsample_bytree': 12    0.3
21    0.3
19    0.7
16    0.3
23    0.7
11    0.7
24    0.7
1     0.3
2     0.3
3     0.7
6     0.7
Name: param_clf__estimator__colsample_bytree, dtype: object, 'param_clf__estimator__booster': 12    gblinear
21    gblinear
19    gblinear
16    gblinear
23    gblinear
11    gblinear
24    gblinear
1     gblinear
2     gblinear
3     gblinear
6     gblinear
Name: param_clf__estimator__booster, dtype: object, 'params': 12    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
21    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
19    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
16    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
23    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
11    {'vectorizer__ngram_range': (1, 3), 'dim_red__...
24    {'vectorizer__ngram_range': (2, 3), 'dim_red__...
1     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
2     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
3     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
6     {'vectorizer__ngram_range': (1, 3), 'dim_red__...
Name: params, dtype: object, 'split0_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
Name: split0_test_score, dtype: float64, 'split1_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
Name: split1_test_score, dtype: float64, 'split2_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
Name: split2_test_score, dtype: float64, 'split3_test_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
Name: split3_test_score, dtype: float64, 'split4_test_score': 12    0.458812
21    0.458812
19    0.458812
16    0.458812
23    0.458812
11    0.458812
24    0.458812
1     0.458812
2     0.458812
3     0.458812
6     0.458812
Name: split4_test_score, dtype: float64, 'mean_test_score': 12    0.459028
21    0.459028
19    0.459028
16    0.459028
23    0.459028
11    0.459028
24    0.459028
1     0.459028
2     0.459028
3     0.459028
6     0.459028
Name: mean_test_score, dtype: float64, 'std_test_score': 12    0.000108
21    0.000108
19    0.000108
16    0.000108
23    0.000108
11    0.000108
24    0.000108
1     0.000108
2     0.000108
3     0.000108
6     0.000108
Name: std_test_score, dtype: float64, 'rank_test_score': 12    1
21    1
19    1
16    1
23    1
11    1
24    1
1     1
2     1
3     1
6     1
Name: rank_test_score, dtype: int32, 'split0_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
Name: split0_train_score, dtype: float64, 'split1_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
Name: split1_train_score, dtype: float64, 'split2_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
Name: split2_train_score, dtype: float64, 'split3_train_score': 12    0.459014
21    0.459014
19    0.459014
16    0.459014
23    0.459014
11    0.459014
24    0.459014
1     0.459014
2     0.459014
3     0.459014
6     0.459014
Name: split3_train_score, dtype: float64, 'split4_train_score': 12    0.459082
21    0.459082
19    0.459082
16    0.459082
23    0.459082
11    0.459082
24    0.459082
1     0.459082
2     0.459082
3     0.459082
6     0.459082
Name: split4_train_score, dtype: float64, 'mean_train_score': 12    0.459028
21    0.459028
19    0.459028
16    0.459028
23    0.459028
11    0.459028
24    0.459028
1     0.459028
2     0.459028
3     0.459028
6     0.459028
Name: mean_train_score, dtype: float64, 'std_train_score': 12    0.000027
21    0.000027
19    0.000027
16    0.000027
23    0.000027
11    0.000027
24    0.000027
1     0.000027
2     0.000027
3     0.000027
6     0.000027
Name: std_train_score, dtype: float64}

               feature     tfidf
0                trump  0.016937
1            president  0.011729
2          impeachment  0.010138
3                  new  0.007695
4                  say  0.007188
5           democratic  0.007143
6                 need  0.007033
7             briefing  0.006826
8                 know  0.006762
9                biden  0.006509
10           democrats  0.006424
11                  is  0.006376
12               house  0.006213
13              debate  0.005930
14           need know  0.005923
15                will  0.005750
16              donald  0.005506
17        donald trump  0.005478
18       briefing need  0.005427
19  briefing need know  0.005427
Fitting 5 folds for each of 25 candidates, totalling 125 fits
[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.
[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   26.9s
[Parallel(n_jobs=6)]: Done 125 out of 125 | elapsed:  1.8min finished
Best random Parameters:  {'clf__estimator__n_estimators': 200, 'clf__estimator__min_samples_leaf': 22, 'clf__estimator__max_depth': 3, 'clf__estimator__learning_rate': 0.29387755102040813, 'clf__estimator__colsample_bytree': 0.7}

Best random Score:  0.6401859286917928

{'mean_fit_time': 14     2.469968
10     6.359880
20     6.675933
0      2.389716
19     4.860481
3      1.496722
4      1.478965
21     1.939054
9     10.492928
12     1.019076
1      5.397941
18     9.138459
8      9.724330
17     4.125708
16     6.995154
2      5.582949
7      4.248815
6      1.506444
15     1.464185
11     2.908331
24     7.429551
5      4.797586
13     2.727590
22     1.152103
23     3.686058
Name: mean_fit_time, dtype: float64, 'std_fit_time': 14    0.021978
10    0.037648
20    0.061029
0     0.006413
19    0.291568
3     0.019637
4     0.021413
21    0.046285
9     0.099899
12    0.015241
1     0.047263
18    0.144913
8     0.039360
17    0.031767
16    0.027068
2     0.055825
7     0.012228
6     0.040715
15    0.010610
11    0.031156
24    0.246920
5     0.469334
13    0.168269
22    0.102446
23    0.146104
Name: std_fit_time, dtype: float64, 'mean_score_time': 14    0.051088
10    0.161299
20    0.168540
0     0.051980
19    0.174889
3     0.051782
4     0.052179
21    0.054262
9     0.293532
12    0.030058
1     0.119932
18    0.241948
8     0.384597
17    0.191951
16    0.189669
2     0.212287
7     0.197308
6     0.056544
15    0.054857
11    0.125884
24    0.182329
5     0.179452
13    0.108623
22    0.015673
23    0.131737
Name: mean_score_time, dtype: float64, 'std_score_time': 14    0.002568
10    0.003311
20    0.005052
0     0.001149
19    0.004319
3     0.001735
4     0.002066
21    0.001898
9     0.006324
12    0.001974
1     0.000853
18    0.054289
8     0.007808
17    0.003645
16    0.004795
2     0.005277
7     0.005391
6     0.002150
15    0.001999
11    0.004646
24    0.010359
5     0.019165
13    0.010638
22    0.005112
23    0.010202
Name: std_score_time, dtype: float64, 'param_clf__estimator__n_estimators': 14    200
10    300
20    300
0     200
19    300
3     100
4     100
21    200
9     300
12    100
1     100
18    200
8     300
17    200
16    200
2     200
7     200
6     100
15    100
11    200
24    300
5     200
13    200
22    200
23    200
Name: param_clf__estimator__n_estimators, dtype: object, 'param_clf__estimator__min_samples_leaf': 14    22
10    33
20    35
0     45
19    22
3     52
4     55
21    40
9     45
12    33
1     44
18    22
8     42
17    59
16    51
2     49
7     55
6     27
15    24
11    53
24    54
5     27
13    40
22    26
23    29
Name: param_clf__estimator__min_samples_leaf, dtype: object, 'param_clf__estimator__max_depth': 14     3
10     6
20     6
0      3
19     6
3      6
4      6
21     3
9     10
12     3
1     20
18    20
8     20
17    10
16    10
2     20
7     10
6      6
15     6
11     6
24    10
5     20
13     6
22     3
23    20
Name: param_clf__estimator__max_depth, dtype: object, 'param_clf__estimator__learning_rate': 14    0.293878
10         0.1
20    0.138776
0     0.487755
19    0.216327
3     0.565306
4     0.565306
21     1.03061
9      0.44898
12     1.53469
1     0.991837
18    0.953061
8     0.526531
17    0.410204
16     1.03061
2      1.41837
7      1.22449
6      1.37959
15     1.41837
11      1.6898
24     1.88367
5      1.80612
13     1.80612
22     1.96122
23           2
Name: param_clf__estimator__learning_rate, dtype: object, 'param_clf__estimator__colsample_bytree': 14    0.7
10    0.7
20    0.7
0     0.7
19    0.3
3     0.3
4     0.3
21    0.3
9     0.7
12    0.3
1     0.7
18    0.7
8     0.3
17    0.3
16    0.7
2     0.3
7     0.3
6     0.3
15    0.3
11    0.3
24    0.7
5     0.3
13    0.3
22    0.3
23    0.3
Name: param_clf__estimator__colsample_bytree, dtype: object, 'params': 14    {'clf__estimator__n_estimators': 200, 'clf__es...
10    {'clf__estimator__n_estimators': 300, 'clf__es...
20    {'clf__estimator__n_estimators': 300, 'clf__es...
0     {'clf__estimator__n_estimators': 200, 'clf__es...
19    {'clf__estimator__n_estimators': 300, 'clf__es...
3     {'clf__estimator__n_estimators': 100, 'clf__es...
4     {'clf__estimator__n_estimators': 100, 'clf__es...
21    {'clf__estimator__n_estimators': 200, 'clf__es...
9     {'clf__estimator__n_estimators': 300, 'clf__es...
12    {'clf__estimator__n_estimators': 100, 'clf__es...
1     {'clf__estimator__n_estimators': 100, 'clf__es...
18    {'clf__estimator__n_estimators': 200, 'clf__es...
8     {'clf__estimator__n_estimators': 300, 'clf__es...
17    {'clf__estimator__n_estimators': 200, 'clf__es...
16    {'clf__estimator__n_estimators': 200, 'clf__es...
2     {'clf__estimator__n_estimators': 200, 'clf__es...
7     {'clf__estimator__n_estimators': 200, 'clf__es...
6     {'clf__estimator__n_estimators': 100, 'clf__es...
15    {'clf__estimator__n_estimators': 100, 'clf__es...
11    {'clf__estimator__n_estimators': 200, 'clf__es...
24    {'clf__estimator__n_estimators': 300, 'clf__es...
5     {'clf__estimator__n_estimators': 200, 'clf__es...
13    {'clf__estimator__n_estimators': 200, 'clf__es...
22    {'clf__estimator__n_estimators': 200, 'clf__es...
23    {'clf__estimator__n_estimators': 200, 'clf__es...
Name: params, dtype: object, 'split0_test_score': 14    0.651198
10    0.649701
20    0.646208
0     0.638224
19    0.636727
3     0.631238
4     0.631238
21    0.629741
9     0.626248
12    0.625250
1     0.604790
18    0.605289
8     0.595808
17    0.606786
16    0.599800
2     0.590319
7     0.592814
6     0.589820
15    0.602794
11    0.576347
24    0.581337
5     0.551896
13    0.551896
22    0.445110
23    0.600299
Name: split0_test_score, dtype: float64, 'split1_test_score': 14    0.646208
10    0.645709
20    0.628743
0     0.634232
19    0.622754
3     0.617764
4     0.617764
21    0.604291
9     0.612275
12    0.592814
1     0.604790
18    0.606287
8     0.603293
17    0.602295
16    0.593812
2     0.590319
7     0.591816
6     0.589820
15    0.580838
11    0.589820
24    0.584830
5     0.578842
13    0.566367
22    0.459082
23    0.241517
Name: split1_test_score, dtype: float64, 'split2_test_score': 14    0.639721
10    0.633733
20    0.622255
0     0.628743
19    0.608283
3     0.602295
4     0.602295
21    0.604790
9     0.590818
12    0.589820
1     0.590818
18    0.589820
8     0.566866
17    0.572355
16    0.580838
2     0.565868
7     0.561876
6     0.565868
15    0.552894
11    0.562375
24    0.558882
5     0.554391
13    0.538423
22    0.459082
23    0.591317
Name: split2_test_score, dtype: float64, 'split3_test_score': 14    0.600798
10    0.593812
20    0.593812
0     0.573353
19    0.566367
3     0.569860
4     0.569860
21    0.567864
9     0.560878
12    0.561876
1     0.565369
18    0.553892
8     0.565369
17    0.563872
16    0.554391
2     0.557884
7     0.540918
6     0.547904
15    0.542415
11    0.538423
24    0.546906
5     0.551397
13    0.504990
22    0.580339
23    0.219062
Name: split3_test_score, dtype: float64, 'split4_test_score': 14    0.663005
10    0.660509
20    0.650025
0     0.642536
19    0.648527
3     0.640539
4     0.640539
21    0.633550
9     0.623065
12    0.632551
1     0.626061
18    0.621568
8     0.644034
17    0.629056
16    0.626061
2     0.627059
7     0.626061
6     0.617574
15    0.610085
11    0.597604
24    0.588118
5     0.607089
13    0.582127
22    0.452821
23    0.575637
Name: split4_test_score, dtype: float64, 'mean_test_score': 14    0.640186
10    0.636693
20    0.628209
0     0.623417
19    0.616532
3     0.612339
4     0.612339
21    0.608047
9     0.602657
12    0.600462
1     0.598366
18    0.595371
8     0.595074
17    0.594873
16    0.590981
2     0.586290
7     0.582697
6     0.582197
15    0.577805
11    0.572914
24    0.572015
5     0.568723
13    0.548761
22    0.479287
23    0.445566
Name: mean_test_score, dtype: float64, 'std_test_score': 14    0.021118
10    0.023088
20    0.020093
0     0.025442
19    0.028477
3     0.024848
4     0.024848
21    0.023496
9     0.024295
12    0.025709
1     0.019977
18    0.023044
8     0.028786
17    0.023806
16    0.023487
2     0.024160
7     0.029137
6     0.023708
15    0.026641
11    0.021014
24    0.016207
5     0.021740
13    0.026290
22    0.050787
23    0.176093
Name: std_test_score, dtype: float64, 'rank_test_score': 14     1
10     2
20     3
0      4
19     5
3      6
4      6
21     8
9      9
12    10
1     11
18    12
8     13
17    14
16    15
2     16
7     17
6     18
15    19
11    20
24    21
5     22
13    23
22    24
23    25
Name: rank_test_score, dtype: int32, 'split0_train_score': 14    0.751092
10    0.873612
20    0.915159
0     0.799376
19    0.872988
3     0.857642
4     0.857642
21    0.799376
9     1.000000
12    0.759451
1     1.000000
18    1.000000
8     1.000000
17    0.998004
16    1.000000
2     1.000000
7     1.000000
6     0.952215
15    0.950218
11    0.999875
24    1.000000
5     0.711167
13    0.965814
22    0.443169
23    0.814099
Name: split0_train_score, dtype: float64, 'split1_train_score': 14    0.752464
10    0.870493
20    0.922396
0     0.803618
19    0.873487
3     0.847536
4     0.847536
21    0.800873
9     1.000000
12    0.757080
1     1.000000
18    1.000000
8     1.000000
17    0.995758
16    1.000000
2     1.000000
7     1.000000
6     0.947973
15    0.953462
11    0.999626
24    1.000000
5     1.000000
13    0.716656
22    0.459014
23    0.241048
Name: split1_train_score, dtype: float64, 'split2_train_score': 14    0.756831
10    0.872489
20    0.913537
0     0.802371
19    0.873862
3     0.852527
4     0.852527
21    0.807236
9     1.000000
12    0.766812
1     1.000000
18    1.000000
8     1.000000
17    0.997505
16    1.000000
2     1.000000
7     1.000000
6     0.950468
15    0.955833
11    0.999750
24    1.000000
5     1.000000
13    0.796007
22    0.464255
23    0.814223
Name: split2_train_score, dtype: float64, 'split3_train_score': 14    0.758702
10    0.873362
20    0.921522
0     0.800499
19    0.869744
3     0.851903
4     0.851903
21    0.810480
9     1.000000
12    0.768060
1     1.000000
18    1.000000
8     1.000000
17    0.995633
16    1.000000
2     1.000000
7     1.000000
6     0.957954
15    0.954336
11    0.999501
24    1.000000
5     1.000000
13    0.859513
22    0.607735
23    0.238927
Name: split3_train_score, dtype: float64, 'split4_train_score': 14    0.748877
10    0.861901
20    0.912550
0     0.790544
19    0.867141
3     0.851297
4     0.851297
21    0.800649
9     1.000000
12    0.755489
1     1.000000
18    1.000000
8     1.000000
17    0.995135
16    1.000000
2     1.000000
7     1.000000
6     0.944611
15    0.951098
11    0.999626
24    1.000000
5     1.000000
13    0.803643
22    0.460080
23    0.791043
Name: split4_train_score, dtype: float64, 'mean_train_score': 14    0.753593
10    0.870372
20    0.917033
0     0.799282
19    0.871444
3     0.852181
4     0.852181
21    0.803723
9     1.000000
12    0.761379
1     1.000000
18    1.000000
8     1.000000
17    0.996407
16    1.000000
2     1.000000
7     1.000000
6     0.950644
15    0.952989
11    0.999676
24    1.000000
5     0.942233
13    0.828327
22    0.486851
23    0.579868
Name: mean_train_score, dtype: float64, 'std_train_score': 14    0.003643
10    0.004375
20    0.004117
0     0.004608
19    0.002600
3     0.003237
4     0.003237
21    0.004347
9     0.000000
12    0.005119
1     0.000000
18    0.000000
8     0.000000
17    0.001131
16    0.000000
2     0.000000
7     0.000000
6     0.004460
15    0.002068
11    0.000127
24    0.000000
5     0.115533
13    0.082462
22    0.060866
23    0.277640
Name: std_train_score, dtype: float64}

{'params': 14    {'clf__estimator__n_estimators': 200, 'clf__es...
10    {'clf__estimator__n_estimators': 300, 'clf__es...
20    {'clf__estimator__n_estimators': 300, 'clf__es...
0     {'clf__estimator__n_estimators': 200, 'clf__es...
19    {'clf__estimator__n_estimators': 300, 'clf__es...
3     {'clf__estimator__n_estimators': 100, 'clf__es...
4     {'clf__estimator__n_estimators': 100, 'clf__es...
21    {'clf__estimator__n_estimators': 200, 'clf__es...
9     {'clf__estimator__n_estimators': 300, 'clf__es...
12    {'clf__estimator__n_estimators': 100, 'clf__es...
1     {'clf__estimator__n_estimators': 100, 'clf__es...
18    {'clf__estimator__n_estimators': 200, 'clf__es...
8     {'clf__estimator__n_estimators': 300, 'clf__es...
17    {'clf__estimator__n_estimators': 200, 'clf__es...
16    {'clf__estimator__n_estimators': 200, 'clf__es...
2     {'clf__estimator__n_estimators': 200, 'clf__es...
7     {'clf__estimator__n_estimators': 200, 'clf__es...
6     {'clf__estimator__n_estimators': 100, 'clf__es...
15    {'clf__estimator__n_estimators': 100, 'clf__es...
11    {'clf__estimator__n_estimators': 200, 'clf__es...
24    {'clf__estimator__n_estimators': 300, 'clf__es...
5     {'clf__estimator__n_estimators': 200, 'clf__es...
13    {'clf__estimator__n_estimators': 200, 'clf__es...
22    {'clf__estimator__n_estimators': 200, 'clf__es...
23    {'clf__estimator__n_estimators': 200, 'clf__es...
Name: params, dtype: object}

{'mean_fit_time': 14    2.469968
Name: mean_fit_time, dtype: float64, 'std_fit_time': 14    0.021978
Name: std_fit_time, dtype: float64, 'mean_score_time': 14    0.051088
Name: mean_score_time, dtype: float64, 'std_score_time': 14    0.002568
Name: std_score_time, dtype: float64, 'param_clf__estimator__n_estimators': 14    200
Name: param_clf__estimator__n_estimators, dtype: object, 'param_clf__estimator__min_samples_leaf': 14    22
Name: param_clf__estimator__min_samples_leaf, dtype: object, 'param_clf__estimator__max_depth': 14    3
Name: param_clf__estimator__max_depth, dtype: object, 'param_clf__estimator__learning_rate': 14    0.293878
Name: param_clf__estimator__learning_rate, dtype: object, 'param_clf__estimator__colsample_bytree': 14    0.7
Name: param_clf__estimator__colsample_bytree, dtype: object, 'params': 14    {'clf__estimator__n_estimators': 200, 'clf__es...
Name: params, dtype: object, 'split0_test_score': 14    0.651198
Name: split0_test_score, dtype: float64, 'split1_test_score': 14    0.646208
Name: split1_test_score, dtype: float64, 'split2_test_score': 14    0.639721
Name: split2_test_score, dtype: float64, 'split3_test_score': 14    0.600798
Name: split3_test_score, dtype: float64, 'split4_test_score': 14    0.663005
Name: split4_test_score, dtype: float64, 'mean_test_score': 14    0.640186
Name: mean_test_score, dtype: float64, 'std_test_score': 14    0.021118
Name: std_test_score, dtype: float64, 'rank_test_score': 14    1
Name: rank_test_score, dtype: int32, 'split0_train_score': 14    0.751092
Name: split0_train_score, dtype: float64, 'split1_train_score': 14    0.752464
Name: split1_train_score, dtype: float64, 'split2_train_score': 14    0.756831
Name: split2_train_score, dtype: float64, 'split3_train_score': 14    0.758702
Name: split3_train_score, dtype: float64, 'split4_train_score': 14    0.748877
Name: split4_train_score, dtype: float64, 'mean_train_score': 14    0.753593
Name: mean_train_score, dtype: float64, 'std_train_score': 14    0.003643
Name: std_train_score, dtype: float64}

{'importance': subjectivity    0.305425
month           0.117244
word_count      0.105319
day             0.101039
char_count      0.100051
hour            0.098209
dayofweek       0.096854
year            0.075860
Name: importance, dtype: float32}
DataFrame shape: (2004, 10)

DataFrame head:                                               text_feat  ...  sentiment_label
7809  Lisa Page Ex Lawyer Whose Texts Criticized Tru...  ...          neutral
5590  This Mexican Chef Is Having a Very Good Year G...  ...          neutral
3329  Why be Democrats Talking About Impeachment Bec...  ...         positive
1728  Democratic Presidential Hopeful Klobuchar Sets...  ...          neutral
9926  Jeffrey Epstein Gun Control Simone Biles Your ...  ...          neutral

[5 rows x 10 columns]

DataFrame labels; positive    937
neutral     717
negative    350
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
1922   Elizabeth Warren Wants to Cancel Student Loans...  ...          neutral
10223  Trump Presses His Argument of a Border Crisis ...  ...          neutral
8313   Big Business Says It Will Tackle Climate Chang...  ...          neutral
2055   Unable to Post Bail You Will Pay for That for ...  ...         negative
1951   Eliminating Child Poverty With a Government Ch...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    908
neutral     703
negative    393
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
10432  The Impeachment Questions We Were Afraid to As...  ...         positive
1304   Who Won the Debate Experts Weigh In There be l...  ...         positive
9176   Years Later Native American Tribe in Montana G...  ...          neutral
2669   In a Collection of Tributes the Gang Is All He...  ...         positive
8691   Trial date be set for Lev Parnas Parnas have s...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    907
neutral     697
negative    400
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                               text_feat  ...  sentiment_label
5266  How Can You Put Life of Onstage With Puppets I...  ...          neutral
1432  Momentum for Harris Big Haul for Buttigieg Thi...  ...         negative
1515  Should College Be Free The Democratic Party be...  ...          neutral
7793  Trump Possible Policy Shift on the Taliban A r...  ...         positive
5133  You Oughta The Road to Making a Anthem a Broad...  ...          neutral

[5 rows x 10 columns]

DataFrame labels; positive    910
neutral     733
negative    361
Name: sentiment_label, dtype: int64

DataFrame shape: (2004, 10)

DataFrame head:                                                text_feat  ...  sentiment_label
7242   Impeachment Briefing What Happened Today Anoth...  ...         positive
10153  Wartime Secrets and Intrigue From the Hotel Ri...  ...         positive
4061   Joe Biden and the Apologies That be Politician...  ...         negative
6344   Elizabeth Warren Has a Poet on Her Team Here W...  ...          neutral
10739  Trump Wants a Fight Pelosi Can Hit Back With r...  ...         positive

[5 rows x 10 columns]

DataFrame labels; positive    935
neutral     715
negative    354
Name: sentiment_label, dtype: int64

Split DataFrames into 5-Fold datasets!

Stacked Model Training!

Text Model!
Pipeline(memory=None,
         steps=[('vectorizer',
                 TfidfVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.float64'>,
                                 encoding='utf-8', input='content',
                                 lowercase=True, max_df=1.0, max_features=None,
                                 min_df=1, ngram_range=(1, 3), norm='l2',
                                 preprocessor=None, smooth_idf=True,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be...
                                                             colsample_bynode=1,
                                                             colsample_bytree=0.3,
                                                             gamma=0,
                                                             learning_rate=0.8395973154362416,
                                                             max_delta_step=0,
                                                             max_depth=6,
                                                             min_child_weight=1,
                                                             min_samples_leaf=48,
                                                             missing=None,
                                                             n_estimators=300,
                                                             n_jobs=1,
                                                             nthread=None,
                                                             objective='binary:logistic',
                                                             random_state=42,
                                                             reg_alpha=0,
                                                             reg_lambda=1,
                                                             scale_pos_weight=1,
                                                             seed=None,
                                                             silent=None,
                                                             subsample=1,
                                                             verbosity=1),
                                     n_jobs=None))],
         verbose=False)

Numeric Model!
Pipeline(memory=None,
         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),
                ('clf',
                 OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5,
                                                             booster='gbtree',
                                                             colsample_bylevel=1,
                                                             colsample_bynode=1,
                                                             colsample_bytree=0.7,
                                                             gamma=0,
                                                             learning_rate=0.29387755102040813,
                                                             max_delta_step=0,
                                                             max_depth=3,
                                                             min_child_weight=1,
                                                             min_samples_leaf=22,
                                                             missing=None,
                                                             n_estimators=200,
                                                             n_jobs=1,
                                                             nthread=None,
                                                             objective='binary:logistic',
                                                             random_state=42,
                                                             reg_alpha=0,
                                                             reg_lambda=1,
                                                             scale_pos_weight=1,
                                                             seed=None,
                                                             silent=None,
                                                             subsample=1,
                                                             verbosity=1),
                                     n_jobs=None))],
         verbose=False)

Test set shape: (401, 9)

Training set 1 shape: (801, 10)

Training set 2 shape: (802, 10)

C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:344: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['text_pred'] = text_model.predict(X_test[text_feature])
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:351: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['num_pred'] = num_model.predict(X_test[num_features])
Stacked Model!
OneVsRestClassifier(estimator=LogisticRegression(C=100, class_weight='balanced',
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=5000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='liblinear', tol=0.0001,
                                                 verbose=0, warm_start=False),
                    n_jobs=None)
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:361: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['stacking'] = stacked_model.predict(X_test[['text_pred', 'num_pred']])
C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
LogisticRegression Coefs: [[-0.00494819  0.02497129]
 [ 0.14006012 -0.78364316]
 [-0.13487947  0.6575238 ]]

Training Set Accuracy
0.6172069825436409

Test Set Accuracy
0.6034912718204489

Confusion matrix
[[  0  24  43]
 [  0  96  44]
 [  0  48 146]]

Classification report
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        67
           0       0.57      0.69      0.62       140
           1       0.63      0.75      0.68       194

    accuracy                           0.60       401
   macro avg       0.40      0.48      0.44       401
weighted avg       0.50      0.60      0.55       401



Test set shape: (401, 9)

Training set 1 shape: (801, 10)

Training set 2 shape: (802, 10)

C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:344: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['text_pred'] = text_model.predict(X_test[text_feature])
Stacked Model!
OneVsRestClassifier(estimator=LogisticRegression(C=100, class_weight='balanced',
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=5000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='liblinear', tol=0.0001,
                                                 verbose=0, warm_start=False),
                    n_jobs=None)
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:351: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['num_pred'] = num_model.predict(X_test[num_features])
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:361: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['stacking'] = stacked_model.predict(X_test[['text_pred', 'num_pred']])
LogisticRegression Coefs: [[-0.05235808  0.23004762]
 [ 0.15045798 -0.80693833]
 [-0.11089476  0.50766776]]

Training Set Accuracy
0.5798004987531172

Test Set Accuracy
0.6034912718204489

Confusion matrix
[[  0  24  44]
 [  0 106  39]
 [  0  52 136]]

Classification report
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        68
           0       0.58      0.73      0.65       145
           1       0.62      0.72      0.67       188

    accuracy                           0.60       401
   macro avg       0.40      0.48      0.44       401
weighted avg       0.50      0.60      0.55       401



Test set shape: (401, 9)

Training set 1 shape: (801, 10)

Training set 2 shape: (802, 10)

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:344: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['text_pred'] = text_model.predict(X_test[text_feature])
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:351: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['num_pred'] = num_model.predict(X_test[num_features])
Stacked Model!
OneVsRestClassifier(estimator=LogisticRegression(C=100, class_weight='balanced',
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=5000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='liblinear', tol=0.0001,
                                                 verbose=0, warm_start=False),
                    n_jobs=None)
LogisticRegression Coefs: [[-0.00521851  0.02410786]
 [ 0.14201876 -0.73757878]
 [-0.13540544  0.60215246]]

Training Set Accuracy
0.5785536159600998

Test Set Accuracy
0.5660847880299252

Confusion matrix
[[  0  32  55]
 [  0  85  44]
 [  0  43 142]]

Classification report
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:361: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['stacking'] = stacked_model.predict(X_test[['text_pred', 'num_pred']])
C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        87
           0       0.53      0.66      0.59       129
           1       0.59      0.77      0.67       185

    accuracy                           0.57       401
   macro avg       0.37      0.48      0.42       401
weighted avg       0.44      0.57      0.50       401



Test set shape: (401, 9)

Training set 1 shape: (801, 10)

Training set 2 shape: (802, 10)

C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:344: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['text_pred'] = text_model.predict(X_test[text_feature])
Stacked Model!
OneVsRestClassifier(estimator=LogisticRegression(C=100, class_weight='balanced',
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=5000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='liblinear', tol=0.0001,
                                                 verbose=0, warm_start=False),
                    n_jobs=None)
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:351: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['num_pred'] = num_model.predict(X_test[num_features])
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:361: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['stacking'] = stacked_model.predict(X_test[['text_pred', 'num_pred']])
C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
LogisticRegression Coefs: [[-0.08665241  0.31969267]
 [ 0.32839141 -1.48041104]
 [-0.26965105  1.00798877]]

Training Set Accuracy
0.600997506234414

Test Set Accuracy
0.5835411471321695

Confusion matrix
[[  0  19  50]
 [  0 108  38]
 [  0  60 126]]

Classification report
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        69
           0       0.58      0.74      0.65       146
           1       0.59      0.68      0.63       186

    accuracy                           0.58       401
   macro avg       0.39      0.47      0.43       401
weighted avg       0.48      0.58      0.53       401



Test set shape: (401, 9)

Training set 1 shape: (801, 10)

Training set 2 shape: (802, 10)

C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:344: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['text_pred'] = text_model.predict(X_test[text_feature])
Stacked Model!
OneVsRestClassifier(estimator=LogisticRegression(C=100, class_weight='balanced',
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=5000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='liblinear', tol=0.0001,
                                                 verbose=0, warm_start=False),
                    n_jobs=None)
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:351: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['num_pred'] = num_model.predict(X_test[num_features])
C:\Users\bscard\Documents\Pycharm Projects\nyt_sentiment_analyzer\model_utils\model_eval.py:361: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X_test['stacking'] = stacked_model.predict(X_test[['text_pred', 'num_pred']])
LogisticRegression Coefs: [[-0.14197742  0.51978443]
 [ 0.20634019 -0.97056485]
 [-0.12567024  0.5229917 ]]

Training Set Accuracy
0.587281795511222

Test Set Accuracy
0.5860349127182045

Confusion matrix
[[  0  25  43]
 [  0  92  45]
 [  0  53 143]]

Classification report
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        68
           0       0.54      0.67      0.60       137
           1       0.62      0.73      0.67       196

    accuracy                           0.59       401
   macro avg       0.39      0.47      0.42       401
weighted avg       0.49      0.59      0.53       401



5-fold cross-validated Accuracy: 0.5885286783042394

5-fold cross-validated F1 score: 0.5885286783042394

C:\Users\bscard\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loaded Text model!
Pipeline(memory=None,
         steps=[('vectorizer',
                 TfidfVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.float64'>,
                                 encoding='utf-8', input='content',
                                 lowercase=True, max_df=1.0, max_features=None,
                                 min_df=1, ngram_range=(1, 3), norm='l2',
                                 preprocessor=None, smooth_idf=True,
                                 stop_words=['a', 'about', 'above', 'after',
                                             'again', 'all', 'also', 'be...
                                                             colsample_bynode=1,
                                                             colsample_bytree=0.3,
                                                             gamma=0,
                                                             learning_rate=0.8395973154362416,
                                                             max_delta_step=0,
                                                             max_depth=6,
                                                             min_child_weight=1,
                                                             min_samples_leaf=48,
                                                             missing=nan,
                                                             n_estimators=300,
                                                             n_jobs=1,
                                                             nthread=None,
                                                             objective='binary:logistic',
                                                             random_state=42,
                                                             reg_alpha=0,
                                                             reg_lambda=1,
                                                             scale_pos_weight=1,
                                                             seed=None,
                                                             silent=None,
                                                             subsample=1,
                                                             verbosity=1),
                                     n_jobs=None))],
         verbose=False)

Loaded Text model!
Pipeline(memory=None,
         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),
                ('clf',
                 OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5,
                                                             booster='gbtree',
                                                             colsample_bylevel=1,
                                                             colsample_bynode=1,
                                                             colsample_bytree=0.7,
                                                             gamma=0,
                                                             learning_rate=0.29387755102040813,
                                                             max_delta_step=0,
                                                             max_depth=3,
                                                             min_child_weight=1,
                                                             min_samples_leaf=22,
                                                             missing=nan,
                                                             n_estimators=200,
                                                             n_jobs=1,
                                                             nthread=None,
                                                             objective='binary:logistic',
                                                             random_state=42,
                                                             reg_alpha=0,
                                                             reg_lambda=1,
                                                             scale_pos_weight=1,
                                                             seed=None,
                                                             silent=None,
                                                             subsample=1,
                                                             verbosity=1),
                                     n_jobs=None))],
         verbose=False)

Loaded Stacked model!
OneVsRestClassifier(estimator=LogisticRegression(C=100, class_weight='balanced',
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=5000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='liblinear', tol=0.0001,
                                                 verbose=0, warm_start=False),
                    n_jobs=None)

(10019, 27)

Index(['headline_main', 'web_url', 'text', 'word_count_SOURCE', 'pub_date',
       'candidate', 'year_SOURCE', 'month_SOURCE', 'day_SOURCE',
       'dayofweek_SOURCE', 'hour_SOURCE', 'polarity', 'subjectivity_SOURCE',
       'sentiment_label_SOURCE', 'char_count_SOURCE', 'text_feat_SOURCE',
       'predictions', 'text_feat_FEAT', 'year_FEAT', 'month_FEAT', 'day_FEAT',
       'dayofweek_FEAT', 'hour_FEAT', 'word_count_FEAT', 'subjectivity_FEAT',
       'char_count_FEAT', 'sentiment_label_FEAT'],
      dtype='object')

candidate
Bernie Sanders      0.730813
Andrew Yang         0.725824
Amy Klobuchar       0.699352
Joe Biden           0.686747
Cory Booker         0.680730
Elizabeth Warren    0.648789
Donald Trump        0.615361
Name: predictions, dtype: float64


Process finished with exit code 0